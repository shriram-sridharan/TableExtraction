=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="0" height="26" left="207" textpieces="0" top="108" width="500">Design and Evaluation of Main Memory</text>
2 <text font="0" height="26" left="189" textpieces="0" top="138" width="536">Hash Join Algorithms for Multi-core CPUs</text>
2 <text font="1" height="17" left="256" textpieces="2" top="206" width="403">Spyros Blanas      Yinan Li      Jignesh M. Patel</text>
2 <text font="2" height="14" left="348" textpieces="0" top="224" width="219">University of WisconsinMadison</text>
2 <text font="1" height="17" left="306" textpieces="0" top="240" width="303">{sblanas, yinan, jignesh}@cs.wisc.edu</text>
2 <text font="1" height="16" left="81" textpieces="0" top="312" width="97">ABSTRACT</text>
2 <text font="3" height="13" left="81" textpieces="0" top="336" width="358">The focus of this paper is on investigating ecient hash join</text>
2 <text font="3" height="13" left="81" textpieces="0" top="352" width="359">algorithms for modern multi-core processors in main mem-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="367" width="359">ory environments. This paper dissects each internal phase</text>
2 <text font="3" height="13" left="81" textpieces="0" top="383" width="359">of a typical hash join algorithm and considers dierent al-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="399" width="358">ternatives for implementing each phase, producing a family</text>
2 <text font="3" height="13" left="81" textpieces="0" top="414" width="359">of hash join algorithms. Then, we implement these main</text>
2 <text font="3" height="13" left="81" textpieces="0" top="430" width="359">memory algorithms on two radically dierent modern multi-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="446" width="359">processor systems, and carefully examine the factors that</text>
2 <text font="3" height="13" left="81" textpieces="0" top="461" width="245">impact the performance of each method.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="477" width="345">Our analysis reveals some interesting results  a very sim-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="493" width="359">ple hash join algorithm is very competitive to the other</text>
2 <text font="3" height="13" left="81" textpieces="0" top="508" width="359">more complex methods. This simple join algorithm builds a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="524" width="358">shared hash table and does not partition the input relations.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="540" width="359">Its simplicity implies that it requires fewer parameter set-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="555" width="359">tings, thereby making it far easier for query optimizers and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="571" width="359">execution engines to use it in practice. Furthermore, the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="587" width="358">performance of this simple algorithm improves dramatically</text>
2 <text font="3" height="13" left="81" textpieces="0" top="603" width="359">as the skew in the input data increases, and it quickly starts</text>
2 <text font="3" height="13" left="81" textpieces="0" top="618" width="359">to outperform all other algorithms. Based on our results,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="634" width="359">we propose that database implementers consider adding this</text>
2 <text font="3" height="13" left="81" textpieces="0" top="650" width="359">simple join algorithm to their repertoire of main memory</text>
2 <text font="3" height="13" left="81" textpieces="0" top="665" width="359">join algorithms, or adapt their methods to mimic the strat-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="681" width="359">egy employed by this algorithm, especially when joining in-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="697" width="220">puts with skewed data distributions.</text>
2 <text font="1" height="16" left="81" textpieces="0" top="731" width="270">Categories and Subject Descriptors</text>
2 <text font="3" height="13" left="81" textpieces="0" top="755" width="359">H.2.4. [Database Management]: SystemsQuery pro-</text>
2 <text font="3" height="12" left="81" textpieces="0" top="771" width="172">cessing, Relational databases</text>
2 <text font="1" height="16" left="81" textpieces="0" top="805" width="114">General Terms</text>
2 <text font="3" height="13" left="81" textpieces="0" top="829" width="200">Algorithms, Design, Performance</text>
2 <text font="1" height="16" left="81" textpieces="0" top="863" width="77">Keywords</text>
2 <text font="3" height="13" left="81" textpieces="0" top="887" width="216">hash join, multi-core, main memory</text>
2 <text font="4" height="11" left="81" textpieces="0" top="976" width="359">Permission to make digital or hard copies of all or part of this work for</text>
2 <text font="4" height="11" left="81" textpieces="0" top="990" width="359">personal or classroom use is granted without fee provided that copies are</text>
2 <text font="4" height="11" left="81" textpieces="0" top="1003" width="358">not made or distributed for prot or commercial advantage and that copies</text>
2 <text font="4" height="11" left="81" textpieces="0" top="1017" width="359">bear this notice and the full citation on the rst page. To copy otherwise, to</text>
2 <text font="4" height="11" left="81" textpieces="0" top="1030" width="358">republish, to post on servers or to redistribute to lists, requires prior specic</text>
2 <text font="4" height="11" left="81" textpieces="0" top="1044" width="115">permission and/or a fee.</text>
2 <text font="4" height="11" left="81" textpieces="1" top="1058" width="235">SIGMOD11,June 1216, 2011, Athens, Greece.</text>
2 <text font="4" height="11" left="81" textpieces="0" top="1071" width="280">Copyright 2011 ACM 978-1-4503-0661-4/11/06 ...$10.00.</text>
=============================== COL ===================================
2 <text font="1" height="16" left="475" textpieces="1" top="312" width="175">1.  INTRODUCTION</text>
2 <text font="3" height="13" left="489" textpieces="0" top="334" width="345">Large scale multi-core processors are imminent. Modern</text>
2 <text font="3" height="13" left="475" textpieces="0" top="349" width="359">processors today already have four or more cores, and for the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="365" width="359">past few years Intel has been introducing two more cores</text>
2 <text font="3" height="13" left="475" textpieces="0" top="381" width="359">per processor roughly every 15 months. At this rate, it</text>
2 <text font="3" height="13" left="475" textpieces="0" top="396" width="359">is not hard to imagine running database management sys-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="412" width="359">tems (DBMSs) on processors with hundreds of cores in the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="428" width="359">near future. In addition, memory prices are continuing to</text>
2 <text font="3" height="13" left="475" textpieces="0" top="444" width="359">drop. Today 1TB of memory costs as little as $25,000. Con-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="459" width="358">sequently, many databases now either t entirely in main</text>
2 <text font="3" height="13" left="475" textpieces="0" top="475" width="359">memory, or their working set is main memory resident. As</text>
2 <text font="3" height="13" left="475" textpieces="0" top="490" width="303">a result, many DBMSs are becoming CPU bound.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="506" width="345">In this evolving architectural landscape, DBMSs have the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="522" width="359">unique opportunity to leverage the inherent parallelism that</text>
2 <text font="3" height="13" left="475" textpieces="0" top="538" width="359">is provided by the relational data model. Data is exposed</text>
2 <text font="3" height="13" left="475" textpieces="0" top="553" width="359">by declarative query languages to user applications and the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="569" width="359">DBMS is free to choose its execution strategy. Coupled</text>
2 <text font="3" height="13" left="475" textpieces="0" top="585" width="359">with the trend towards impending very large multi-cores,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="600" width="359">this implies that DBMSs must carefully rethink how they</text>
2 <text font="3" height="13" left="475" textpieces="0" top="616" width="359">can exploit the parallelism that is provided by the modern</text>
2 <text font="3" height="13" left="475" textpieces="0" top="632" width="332">multi-core processors, or DBMS performance will stall.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="647" width="345">A natural question to ask then is whether there is anything</text>
2 <text font="3" height="13" left="475" textpieces="0" top="663" width="359">new here. Beginning about three decades ago, at the incep-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="679" width="359">tion of the eld of parallel DBMSs, the database community</text>
2 <text font="3" height="13" left="475" textpieces="0" top="694" width="359">thoroughly examined how a DBMS can use various forms of</text>
2 <text font="3" height="13" left="475" textpieces="0" top="710" width="359">parallelism. These forms of parallelism include pure shared-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="726" width="358">nothing, shared-memory, and shared disk architectures [17].</text>
2 <text font="3" height="13" left="475" textpieces="0" top="742" width="359">If the modern multi-core architectures resemble any of these</text>
2 <text font="3" height="13" left="475" textpieces="0" top="757" width="359">architectural templates, then we can simply adopt the meth-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="773" width="223">ods that have already been designed.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="789" width="345">In fact, to a large extent this is the approach that DBMSs</text>
2 <text font="3" height="13" left="475" textpieces="0" top="804" width="359">have haven taken towards dealing with multi-core machines.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="820" width="359">Many commercial DBMSs simply treat a multi-core proces-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="836" width="359">sor as a symmetric multi-processor (SMP) machine, lever-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="851" width="359">aging previous work that was done by the DBMS vendors</text>
2 <text font="3" height="13" left="475" textpieces="0" top="867" width="359">in reaction to the increasing popularity of SMP machines</text>
2 <text font="3" height="13" left="475" textpieces="0" top="883" width="359">decades ago. These methods break up the task of a single</text>
2 <text font="3" height="13" left="475" textpieces="0" top="899" width="358">operation, such as an equijoin, into disjoint parts and allow</text>
2 <text font="3" height="13" left="475" textpieces="0" top="914" width="359">each processor (in an SMP box) to work on each part in-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="930" width="359">dependently. At a high-level, these methods resemble vari-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="946" width="359">ations of query processing techniques that were developed</text>
2 <text font="3" height="13" left="475" textpieces="0" top="961" width="359">for parallel shared-nothing architectures [6], but adapted</text>
2 <text font="3" height="13" left="475" textpieces="0" top="977" width="359">for SMP machines. In most commercial DBMSs, this ap-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="993" width="359">proach is reected across the entire design process, ranging</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1008" width="359">from system internals (join processing, for example) to their</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1024" width="359">pricing model, which is frequently done by scaling the SMP</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1040" width="359">pricing model. On the other hand, open-source DBMSs have</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="3" height="13" left="81" textpieces="0" top="85" width="359">largely ignored multi-core processing and generally dedicate</text>
2 <text font="3" height="13" left="81" textpieces="0" top="101" width="229">a single thread/process to each query.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="117" width="345">The design space for modern high performance main mem-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="133" width="359">ory join algorithms has two extremes. One extreme of this</text>
2 <text font="3" height="13" left="81" textpieces="0" top="148" width="359">design space focuses on minimizing the number of proces-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="164" width="359">sor cache misses. The radix-based hash join algorithm [2] is</text>
2 <text font="3" height="13" left="81" textpieces="0" top="180" width="359">an example of a method in this design class. The other ex-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="195" width="359">treme is to focus on minimizing processor synchronization</text>
2 <text font="3" height="13" left="81" textpieces="0" top="211" width="359">costs. In this paper we propose a no partitioning hash</text>
2 <text font="3" height="13" left="81" textpieces="0" top="227" width="359">join algorithm that does not partition the input relations to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="242" width="356">embody an example of a method in this later design space.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="258" width="345">A crucial question that we ask and answer in this paper</text>
2 <text font="3" height="13" left="81" textpieces="0" top="274" width="359">is what is the impact of these two extreme design points in</text>
2 <text font="3" height="12" left="81" textpieces="0" top="290" width="359">modern multi-core processors for main memory hash join al-</text>
2 <text font="3" height="12" left="81" textpieces="0" top="306" width="359">gorithms. A perhaps surprising answer is that for modern</text>
2 <text font="3" height="13" left="81" textpieces="0" top="321" width="359">multi-core architectures, in many cases the right approach is</text>
2 <text font="3" height="13" left="81" textpieces="0" top="337" width="359">to focus on reducing the computation and synchronization</text>
2 <text font="3" height="13" left="81" textpieces="0" top="352" width="359">costs, as modern processors are very eective in hiding cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="368" width="359">miss latencies via simultaneous multi-threading. For exam-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="384" width="358">ple, in our experiments, the no partitioning hash join algo-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="399" width="359">rithm far outperforms the radix join algorithm when there</text>
2 <text font="3" height="13" left="81" textpieces="0" top="415" width="359">is skew in the data (which is often the case in practice), even</text>
2 <text font="3" height="13" left="81" textpieces="0" top="431" width="358">while it incurs many more processor cache and TLB misses.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="446" width="359">Even with uniform data, the radix join algorithm only out-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="462" width="359">performs the no partitioning algorithm on a modern Intel</text>
2 <text font="3" height="13" left="81" textpieces="0" top="478" width="359">Xeon when the parameters for the radix join algorithm are</text>
2 <text font="3" height="13" left="81" textpieces="0" top="494" width="359">set at or near their optimal setting. In contrast, the non-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="509" width="359">partitioned algorithm is parameter-free, which is another</text>
2 <text font="3" height="13" left="81" textpieces="0" top="525" width="187">important practical advantage.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="541" width="345">Reecting on the previous work in this area, one can ob-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="556" width="359">serve that the database community has focused on optimiz-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="572" width="359">ing query processing methods to reduce the number of pro-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="588" width="359">cessor cache and TLB misses. We hope that this paper opens</text>
2 <text font="3" height="13" left="81" textpieces="0" top="603" width="359">up a new discussion on the entire design space for multi-core</text>
2 <text font="3" height="13" left="81" textpieces="0" top="619" width="359">query processing techniques, and incites a similar examina-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="635" width="359">tion of other aspects of query processing beyond the single</text>
2 <text font="3" height="13" left="81" textpieces="0" top="651" width="299">hash join operation that we discuss in this paper.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="666" width="345">This paper makes three main contributions. First, we sys-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="682" width="359">tematically examine the design choices available for each in-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="697" width="359">ternal phase of a canonical main memory hash join algorithm</text>
2 <text font="3" height="13" left="81" textpieces="0" top="713" width="359"> namely, the partition, build, and probe phases  and enu-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="729" width="359">merate a number of possible multi-core hash join algorithms</text>
2 <text font="3" height="13" left="81" textpieces="0" top="745" width="359">based on dierent choices made in each of these phases. We</text>
2 <text font="3" height="13" left="81" textpieces="0" top="760" width="359">then evaluate these join algorithms on two radically dier-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="776" width="359">ent architectures and show how the architectural dierences</text>
2 <text font="3" height="13" left="81" textpieces="0" top="792" width="359">can aect performance. Unlike previous work that has often</text>
2 <text font="3" height="13" left="81" textpieces="0" top="807" width="359">focused on just one architecture, our use of two radically dif-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="823" width="359">ferent architectures lets us gain deeper insights about hash</text>
2 <text font="3" height="13" left="81" textpieces="0" top="839" width="359">join processing on multi-core processors. To the best of our</text>
2 <text font="3" height="13" left="81" textpieces="0" top="854" width="359">knowledge, this is the rst systematic exploration of multiple</text>
2 <text font="3" height="13" left="81" textpieces="0" top="870" width="342">hash join techniques that spans multi-core architectures.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="886" width="345">Second, we show that an algorithm that does not do any</text>
2 <text font="3" height="13" left="81" textpieces="0" top="901" width="359">partitioning, but simply constructs a single shared hash ta-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="917" width="359">ble on the build relation often outperforms more complex al-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="933" width="359">gorithms. This simple no-partitioning hash join algorithm</text>
2 <text font="3" height="13" left="81" textpieces="0" top="949" width="359">is robust to sub-optimal parameter choices by the optimizer,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="964" width="359">and does not require any knowledge of the characteristics of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="980" width="359">the input to work well. To the best of our knowledge, this</text>
2 <text font="3" height="13" left="81" textpieces="0" top="996" width="359">simple hash join technique diers from what is currently</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1011" width="358">implemented in existing DBMSs for multi-core hash join</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1027" width="359">processing, and oers a tantalizingly simple, ecient, and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1043" width="357">robust technique for implementing the hash join operation.</text>
=============================== COL ===================================
2 <text font="3" height="13" left="489" textpieces="0" top="85" width="345">Finally, we show that the simple no-partitioning hash</text>
2 <text font="3" height="13" left="475" textpieces="0" top="101" width="359">join algorithm takes advantage of intrinsic hardware opti-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="117" width="358">mizations to handle skew. As a result, this simple hash join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="133" width="358">technique often benets from skew and its relative perfor-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="148" width="359">mance increases as the skew increases! This property is a</text>
2 <text font="3" height="13" left="475" textpieces="0" top="164" width="359">big advancement over the state-of-the-art methods, as it is</text>
2 <text font="3" height="13" left="475" textpieces="0" top="180" width="359">important to have methods that can gracefully handle skew</text>
2 <text font="3" height="13" left="475" textpieces="0" top="195" width="86">in practice [8].</text>
2 <text font="3" height="13" left="489" textpieces="0" top="211" width="345">The remainder of this paper is organized as follows: The</text>
2 <text font="3" height="13" left="475" textpieces="0" top="227" width="358">next section covers background information. The hash join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="242" width="359">variants are presented in Section 3. Experimental results are</text>
2 <text font="3" height="13" left="475" textpieces="0" top="258" width="359">described in Section 4, and related work is discussed in Sec-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="274" width="354">tion 5. Finally, Section 6 contains our concluding remarks.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="295" width="305">2.  THE MULTI-CORE LANDSCAPE</text>
2 <text font="3" height="13" left="489" textpieces="0" top="317" width="345">In the last few years alone, more than a dozen dierent</text>
2 <text font="3" height="13" left="475" textpieces="0" top="332" width="359">multi-core CPU families have been introduced by CPU ven-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="348" width="359">dors. These new CPUs have ranged from powerful dual-CPU</text>
2 <text font="3" height="13" left="475" textpieces="0" top="364" width="359">systems on the same die to prototype systems of hundreds</text>
2 <text font="3" height="13" left="475" textpieces="0" top="380" width="130">of simple RISC cores.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="395" width="345">This new level of integration has lead to architectural</text>
2 <text font="3" height="13" left="475" textpieces="0" top="411" width="359">changes with deep impact on algorithm design. Although</text>
2 <text font="3" height="13" left="475" textpieces="0" top="427" width="359">the rst multi-core CPUs had dedicated caches for each core,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="442" width="359">we now see a shift towards more sharing at the lower levels</text>
2 <text font="3" height="13" left="475" textpieces="0" top="458" width="358">of the cache hierarchy and consequently the need for access</text>
2 <text font="3" height="13" left="475" textpieces="0" top="474" width="359">arbitration to shared caches within the chip. A shared cache</text>
2 <text font="3" height="13" left="475" textpieces="0" top="489" width="359">means better single-threaded performance, as one core can</text>
2 <text font="3" height="13" left="475" textpieces="0" top="505" width="359">utilize the whole cache, and more opportunities for sharing</text>
2 <text font="3" height="13" left="475" textpieces="0" top="521" width="359">among cores. However, shared caches also increase conict</text>
2 <text font="3" height="13" left="475" textpieces="0" top="537" width="359">cache misses due to false sharing, and may increase capacity</text>
2 <text font="3" height="13" left="475" textpieces="0" top="552" width="358">cache misses, if the cache sizes dont increase proportionally</text>
2 <text font="3" height="13" left="475" textpieces="0" top="568" width="140">to the number of cores.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="584" width="345">One idea that is employed to combat the diminishing re-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="599" width="359">turns of instruction-level parallelism is simultaneous multi-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="615" width="359">threading (SMT). Multi-threading attempts to nd inde-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="631" width="359">pendent instructions across dierent threads of execution,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="646" width="359">instead of detecting independent instructions in the same</text>
2 <text font="3" height="13" left="475" textpieces="0" top="662" width="359">thread. This way, the CPU will schedule instructions from</text>
2 <text font="3" height="13" left="475" textpieces="0" top="678" width="359">each thread and achieve better overall utilization, increasing</text>
2 <text font="3" height="13" left="475" textpieces="0" top="693" width="295">throughput at the expense of per-thread latency.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="709" width="345">We briey consider two modern architectures that we sub-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="725" width="359">sequently use for evaluation. At one end of the spectrum,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="741" width="359">the Intel Nehalem family is an instance of Intels latest mi-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="756" width="359">croarchitecture that oers high single-threaded performance</text>
2 <text font="3" height="13" left="475" textpieces="0" top="772" width="358">because of its out-of-order execution and on-demand fre-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="787" width="359">quency scaling (TurboBoost). Multi-threaded performance</text>
2 <text font="3" height="13" left="475" textpieces="0" top="803" width="359">is increased by using simultaneous multi-threading (Hyper-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="819" width="359">Threading). At the other end of the spectrum, the Sun</text>
2 <text font="3" height="13" left="475" textpieces="0" top="835" width="359">UltraSPARC T2 has 8 simple cores that all share a sin-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="850" width="359">gle cache. This CPU can execute instructions from up to</text>
2 <text font="3" height="13" left="475" textpieces="0" top="866" width="359">8 threads per core, or a total of 64 threads for the entire</text>
2 <text font="3" height="13" left="475" textpieces="0" top="882" width="359">chip, and extensively relies on simultaneous multi-threading</text>
2 <text font="3" height="13" left="475" textpieces="0" top="897" width="202">to achieve maximum throughput.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="919" width="303">3.  HASH JOIN IMPLEMENTATION</text>
2 <text font="3" height="13" left="489" textpieces="0" top="940" width="345">In this section, we consider the anatomy of a canoni-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="956" width="358">cal hash join algorithm, and carefully consider the design</text>
2 <text font="3" height="13" left="475" textpieces="0" top="972" width="359">choices that are available in each internal phase of a hash</text>
2 <text font="3" height="13" left="475" textpieces="0" top="987" width="359">join algorithm. Then using these design choices, we cat-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1003" width="358">egorize various previous proposals for multi-core hash join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1019" width="358">processing. In the following discussion we also present infor-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1034" width="359">mation about some of the implementation details, as they</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1050" width="359">often have a signicant impact on the performance of the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1066" width="166">technique that is described.</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="3" height="13" left="94" textpieces="0" top="85" width="345">A hash join operator works on two input relations, R and</text>
2 <text font="3" height="12" left="81" textpieces="0" top="102" width="357">S. We assume that |R| &lt; |S|. A typical hash join algorithm</text>
2 <text font="3" height="13" left="81" textpieces="0" top="117" width="359">has three phases: partition, build, and probe. The partition</text>
2 <text font="3" height="13" left="81" textpieces="0" top="133" width="359">phase is optional and divides tuples into distinct sets using</text>
2 <text font="3" height="13" left="81" textpieces="0" top="148" width="359">a hash function on the join key attribute. The build phase</text>
2 <text font="3" height="13" left="81" textpieces="0" top="164" width="359">scans the relation R and creates an in-memory hash table on</text>
2 <text font="3" height="13" left="81" textpieces="0" top="180" width="358">the join key attribute. The probe phase scans the relation</text>
2 <text font="3" height="12" left="81" textpieces="0" top="196" width="357">S, looks up the join key of each tuple in the hash table, and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="211" width="304">in the case of a match creates the output tuple(s).</text>
2 <text font="3" height="13" left="94" textpieces="0" top="227" width="345">Before we discuss the alternative techniques that are avail-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="242" width="359">able in each phase of the join algorithm, we briey digress</text>
2 <text font="3" height="13" left="81" textpieces="0" top="258" width="359">to discuss the impact of the latch implementation on the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="274" width="359">join techniques. As a general comment, we have found that</text>
2 <text font="3" height="13" left="81" textpieces="0" top="290" width="359">the latch implementation has a crucial impact on the over-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="305" width="359">all join performance. In particular, when using the pthreads</text>
2 <text font="3" height="13" left="81" textpieces="0" top="321" width="359">mutex implementation, several instructions are required to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="337" width="359">acquire and release an uncontended latch. If there are mil-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="352" width="359">lions of buckets in a hash table, then the hash collision rate</text>
2 <text font="3" height="13" left="81" textpieces="0" top="368" width="359">is small, and one can optimize for the expected case: latches</text>
2 <text font="3" height="13" left="81" textpieces="0" top="384" width="359">being free. Furthermore, pthread mutexes have signicant</text>
2 <text font="3" height="13" left="81" textpieces="0" top="399" width="359">memory footprint as each requires approximately 40 bytes.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="415" width="359">If each bucket stores a few &lt;key, record-id&gt; pairs, then the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="431" width="359">size of the latch array may be greater than the size of the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="446" width="359">hash table itself. These characteristics make mutexes a pro-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="462" width="359">hibitively expensive synchronization primitive for buckets</text>
2 <text font="3" height="13" left="81" textpieces="0" top="478" width="359">in a hash table. Hence, we implemented our own 1-byte</text>
2 <text font="3" height="13" left="81" textpieces="0" top="494" width="359">latch for both the Intel and the Sun architectures, using the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="509" width="359">atomic primitives xchgb and ldstub, respectively. Protect-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="525" width="359">ing multiple hash buckets with a single latch to avoid cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="541" width="359">thrashing did not result in signicant performance improve-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="556" width="317">ments even when the number of partitions was high.</text>
2 <text font="1" height="16" left="81" textpieces="1" top="589" width="157">3.1  Partition phase</text>
2 <text font="3" height="13" left="94" textpieces="0" top="611" width="345">The partition phase is an optional step of a hash join al-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="627" width="359">gorithm, if the hash table for the relation R ts in main</text>
2 <text font="3" height="13" left="81" textpieces="0" top="642" width="359">memory. If one partitions both the R and S relations such</text>
2 <text font="3" height="13" left="81" textpieces="0" top="658" width="359">that each partition ts in the CPU cache, then the cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="674" width="359">misses that are otherwise incurred during the subsequent</text>
2 <text font="3" height="13" left="81" textpieces="0" top="689" width="359">build and probe phases are almost eliminated. The cost</text>
2 <text font="3" height="13" left="81" textpieces="0" top="705" width="359">for partitioning both input relations is incurring additional</text>
2 <text font="3" height="13" left="81" textpieces="0" top="721" width="359">memory writes for each tuple. Work by Shatdal et al. [16]</text>
2 <text font="3" height="13" left="81" textpieces="0" top="736" width="359">has shown that the runtime cost of the additional memory</text>
2 <text font="3" height="13" left="81" textpieces="0" top="752" width="359">writes during partitioning phase is less than the cost of miss-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="768" width="359">ing in the cache  as a consequence partitioning improves</text>
2 <text font="3" height="13" left="81" textpieces="0" top="783" width="359">overall performance. Recent work by Cieslewicz and Ross</text>
2 <text font="3" height="13" left="81" textpieces="0" top="799" width="359">[4] has explored partitioning performance in detail. They</text>
2 <text font="3" height="13" left="81" textpieces="0" top="815" width="359">introduce two algorithms that process the input once in a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="831" width="359">serial fashion and do not require any kind of global knowl-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="846" width="359">edge about the characteristics of the input. Another recent</text>
2 <text font="3" height="13" left="81" textpieces="0" top="862" width="359">paper [11] describes a parallel implementation of radix par-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="878" width="359">titioning [2] which gives impressive performance improve-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="893" width="359">ments on a modern multi-core system. This implementation</text>
2 <text font="3" height="13" left="81" textpieces="0" top="909" width="359">requires that the entire input is available upfront and will</text>
2 <text font="3" height="13" left="81" textpieces="0" top="925" width="359">not produce any output until the last input tuple has been</text>
2 <text font="3" height="13" left="81" textpieces="0" top="940" width="359">seen. We experiment with all of these three partitioning al-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="956" width="359">gorithms, and we briey summarize each implementation in</text>
2 <text font="3" height="13" left="81" textpieces="0" top="972" width="145">Sections 3.1.1 and 3.1.2.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="987" width="345">In our implementation, a partition is a linked list of output</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1003" width="359">buers. An output buer is fully described by four elements:</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1019" width="359">an integer specifying the size of the data block, a pointer to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">the start of the data block, a pointer to the free space inside</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1050" width="359">the data block and a pointer to the next output buer that</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1066" width="359">is initially set to zero. If a buer overows, then we add an</text>
=============================== COL ===================================
2 <text font="3" height="13" left="475" textpieces="0" top="85" width="359">empty output buer at the start of the list, and we make its</text>
2 <text font="3" height="13" left="475" textpieces="0" top="101" width="359">next pointer point to the buer that overowed. Locating</text>
2 <text font="3" height="13" left="475" textpieces="0" top="117" width="359">free space is a matter of checking the rst buer in the list.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="133" width="345">Let p denote the desired number of partitions and n de-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="148" width="358">note the number of threads that are processing the hash join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="164" width="359">operation. During the partitioning phase, all threads start</text>
2 <text font="3" height="13" left="475" textpieces="0" top="180" width="359">reading tuples from the relation R, via a cursor. Each thread</text>
2 <text font="3" height="13" left="475" textpieces="0" top="195" width="359">works on a large batch of tuples at a time, so as to minimize</text>
2 <text font="3" height="13" left="475" textpieces="0" top="211" width="359">synchronization overheads on the input scan cursor. Each</text>
2 <text font="3" height="13" left="475" textpieces="0" top="227" width="359">thread examines a tuple, then extracts the key k, and -</text>
2 <text font="3" height="13" left="475" textpieces="0" top="242" width="358">nally computes the partitioning hash function hp(k). Next,</text>
2 <text font="3" height="13" left="475" textpieces="1" top="258" width="359">it then writes the tuple to partition Rhp(k)using one of the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="274" width="359">algorithms we describe below. When the R cursor runs out</text>
2 <text font="3" height="13" left="475" textpieces="0" top="290" width="359">of tuples, the partitioning operation proceeds to process the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="305" width="359">tuples from the S relation. Again, each tuple is examined,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="321" width="359">the join key k is extracted and the tuple is written to the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="337" width="359">partition Shp(k). The partitioning phase ends when all the</text>
2 <text font="3" height="12" left="475" textpieces="1" top="353" width="190">S tuples have been partitioned.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="368" width="345">Note that we classify the partitioning algorithms as non-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="384" width="359">blocking if they produce results on-the-y and scan the in-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="399" width="359">put once, in contrast to a blocking algorithm that produces</text>
2 <text font="3" height="13" left="475" textpieces="0" top="415" width="359">results after buering the entire input and scanning it more</text>
2 <text font="3" height="13" left="475" textpieces="0" top="431" width="359">than once. We acknowledge that the join operator overall</text>
2 <text font="3" height="13" left="475" textpieces="0" top="446" width="359">is never truly non-blocking, as it will block during the build</text>
2 <text font="3" height="13" left="475" textpieces="0" top="462" width="358">phase. The distinction is that the non-blocking algorithms</text>
2 <text font="3" height="13" left="475" textpieces="0" top="478" width="359">only block for the time that is needed to scan and process</text>
2 <text font="3" height="13" left="475" textpieces="0" top="494" width="359">the smaller input, and, as we will see in Section 4.3, this a</text>
2 <text font="3" height="13" left="475" textpieces="0" top="509" width="259">very small fraction of the overall join time.</text>
2 <text font="7" height="15" left="479" textpieces="1" top="539" width="215">3.1.1  Non-blocking algorithms</text>
2 <text font="3" height="13" left="489" textpieces="0" top="560" width="345">The rst partitioning algorithm creates p shared partitions</text>
2 <text font="3" height="13" left="475" textpieces="0" top="576" width="359">among all the threads. The threads need to synchronize via</text>
2 <text font="3" height="13" left="475" textpieces="0" top="591" width="359">a latch to make sure that the writes to a shared partition</text>
2 <text font="3" height="13" left="475" textpieces="0" top="607" width="173">are isolated from each other.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="623" width="345">The second partitioning algorithm creates p  n partitions</text>
2 <text font="3" height="13" left="475" textpieces="0" top="638" width="359">in total and each thread is assigned a private set of p parti-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="654" width="359">tions. Each thread then writes to its local partitions without</text>
2 <text font="3" height="13" left="475" textpieces="0" top="670" width="359">any synchronization overhead. When the input relation is</text>
2 <text font="3" height="13" left="475" textpieces="0" top="686" width="359">depleted, all threads synchronize at a barrier to consolidate</text>
2 <text font="3" height="13" left="475" textpieces="0" top="701" width="221">the p  n partitions into p partitions.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="717" width="345">The benet of creating private partitions is that there is</text>
2 <text font="3" height="13" left="475" textpieces="0" top="733" width="359">no synchronization overhead on each access. The drawbacks,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="748" width="359">however, are (a) many partitions are created, possibly so</text>
2 <text font="3" height="13" left="475" textpieces="0" top="764" width="359">many that the working set of the algorithm no longer ts in</text>
2 <text font="3" height="13" left="475" textpieces="0" top="780" width="359">the data cache and the TLB; (b) at the end of the partition</text>
2 <text font="3" height="13" left="475" textpieces="0" top="795" width="359">phase some thread has to chain n private partitions together</text>
2 <text font="3" height="13" left="475" textpieces="0" top="811" width="359">to form a single partition, but this operation is quick and</text>
2 <text font="3" height="13" left="475" textpieces="0" top="827" width="116">can be parallelized.</text>
2 <text font="7" height="15" left="479" textpieces="1" top="857" width="177">3.1.2  Blocking algorithm</text>
2 <text font="3" height="13" left="489" textpieces="0" top="878" width="345">Another partitioning technique is the parallel multi-pass</text>
2 <text font="3" height="13" left="475" textpieces="0" top="893" width="358">radix partitioning algorithm described by Kim et al. [11].</text>
2 <text font="3" height="13" left="475" textpieces="0" top="909" width="359">The algorithm begins by having the entire input available in</text>
2 <text font="3" height="13" left="475" textpieces="0" top="925" width="359">a contiguous block of memory. Each thread is responsible</text>
2 <text font="3" height="13" left="475" textpieces="0" top="940" width="359">for a specic memory region in that contiguous block. A</text>
2 <text font="3" height="13" left="475" textpieces="0" top="956" width="359">histogram with p  n bins is allocated and the input is then</text>
2 <text font="3" height="13" left="475" textpieces="0" top="972" width="359">scanned twice. During the rst scan, each thread scans all</text>
2 <text font="3" height="13" left="475" textpieces="0" top="987" width="359">the tuples in the memory region assigned to it, extracts the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1003" width="359">key k and then computes the exact histogram of the hash</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1019" width="358">values hp(k) for this region. Thread i  [0, n  1] stores the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1034" width="359">number of tuples it encountered that will hash to partition</text>
2 <text font="3" height="12" left="475" textpieces="1" top="1051" width="358">j [0, p1] in histogram bin j n+i. At the end of the scan,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1066" width="359">all the n threads compute the prex sum on the histogram</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="3" height="13" left="81" textpieces="0" top="85" width="359">in parallel. The prex sum can now be used to point to the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="101" width="359">beginning of each output partition for each thread in the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="117" width="359">single shared output buer. Finally, each thread performs</text>
2 <text font="3" height="13" left="81" textpieces="1" top="133" width="358">a second scan of its input region, and uses hpto determine</text>
2 <text font="3" height="13" left="81" textpieces="0" top="148" width="359">the output partition. This algorithm is recursively applied</text>
2 <text font="3" height="13" left="81" textpieces="0" top="164" width="346">to each output partition for as many passes as requested.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="180" width="345">The benet of radix partitioning is that it makes few cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="195" width="359">and TLB misses, as it bounds the number of output destina-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="211" width="359">tions in each pass. This particular implementation has the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="227" width="359">benet that, by scanning the input twice for each pass, it</text>
2 <text font="3" height="13" left="81" textpieces="0" top="242" width="359">computes exactly how much output space will be required for</text>
2 <text font="3" height="13" left="81" textpieces="0" top="258" width="359">each partition, and hence avoids the synchronization over-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="274" width="359">head that is associated with sharing an output buer. Apart</text>
2 <text font="3" height="13" left="81" textpieces="0" top="290" width="359">from the drawbacks that are associated with any blocking</text>
2 <text font="3" height="13" left="81" textpieces="0" top="305" width="359">algorithm when compared to a non-blocking counterpart,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="321" width="359">this implementation also places a burden on the previous</text>
2 <text font="3" height="13" left="81" textpieces="0" top="337" width="359">operator in a query tree to produce the compact and con-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="352" width="359">tiguous output format that the radix partitioning requires</text>
2 <text font="3" height="13" left="81" textpieces="0" top="368" width="359">as input. Eciently producing a single shared output buer</text>
2 <text font="3" height="13" left="81" textpieces="0" top="384" width="274">is a problem that has been studied before [5].</text>
2 <text font="1" height="16" left="81" textpieces="1" top="413" width="130">3.2  Build phase</text>
2 <text font="3" height="13" left="94" textpieces="0" top="435" width="345">The build phase proceeds as follows: If the partition phase</text>
2 <text font="3" height="13" left="81" textpieces="0" top="451" width="359">was omitted, then all the threads are assigned to work on</text>
2 <text font="3" height="13" left="81" textpieces="0" top="467" width="359">the relation R. If partitioning was done, then each thread</text>
2 <text font="3" height="12" left="81" textpieces="1" top="483" width="358">iis assigned to work on partitions Ri+0n, Ri+1n, Ri+2n,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="498" width="359">etc. For example, a machine with four cores has n = 4, and</text>
2 <text font="3" height="13" left="81" textpieces="1" top="514" width="359">thread 0 would work on partitions R0, R4, R8, ..., thread 1</text>
2 <text font="3" height="13" left="81" textpieces="1" top="529" width="129">on R1, R5, R9, ..., etc.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="545" width="345">Next, an empty hash table is constructed for each parti-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="561" width="359">tion of the input relation R. To reduce the number of cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="577" width="359">misses that are incurred during the next (probe) phase, each</text>
2 <text font="3" height="13" left="81" textpieces="0" top="592" width="359">bucket of this hash table is sized so that it ts on a few cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="608" width="359">lines. Each thread scans every tuple t in its partition, ex-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="624" width="359">tracts the join key k, and then hashes this key using a hash</text>
2 <text font="3" height="13" left="81" textpieces="0" top="639" width="359">function h(). Then, the tuple t is appended to the end of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="655" width="359">the hash bucket h(k), creating a new hash bucket if neces-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="671" width="359">sary. If the partition phase was omitted, then all the threads</text>
2 <text font="3" height="13" left="81" textpieces="0" top="686" width="359">share the hash table, and writes to each hash bucket have</text>
2 <text font="3" height="13" left="81" textpieces="0" top="702" width="359">to be protected by a latch. The build phase is over when all</text>
2 <text font="3" height="13" left="81" textpieces="0" top="718" width="340">the n threads have processed all the assigned partitions.</text>
2 <text font="1" height="16" left="81" textpieces="1" top="746" width="134">3.3  Probe phase</text>
2 <text font="3" height="13" left="94" textpieces="0" top="768" width="345">The probe phase schedules work to the n threads in a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="783" width="359">manner similar to the scheduling during the build phase,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="799" width="359">described above. Namely, if no partitioning has been done,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="815" width="359">then all the threads are assigned to S, and they synchronize</text>
2 <text font="3" height="13" left="81" textpieces="0" top="831" width="359">before accessing the read cursor for S. Otherwise, the thread</text>
2 <text font="3" height="12" left="81" textpieces="1" top="847" width="323">iis assigned to partitions Si+0n, Si+1n, Si+2n, etc.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="862" width="345">During the probe phase, each thread reads every tuple s</text>
2 <text font="3" height="13" left="81" textpieces="0" top="878" width="359">from its assigned partition and extracts the key k. It then</text>
2 <text font="3" height="13" left="81" textpieces="0" top="893" width="359">checks if the key of each tuple r stored in hash bucket h(k)</text>
2 <text font="3" height="13" left="81" textpieces="0" top="909" width="359">matches k. This check is necessary to lter out possible</text>
2 <text font="3" height="13" left="81" textpieces="0" top="925" width="359">hash collisions. If the keys match, then the tuples r and s</text>
2 <text font="3" height="13" left="81" textpieces="0" top="940" width="359">are joined to form the output tuple. If the output is mate-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="956" width="359">rialized, it is written to an output buer that is private to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="972" width="67">the thread.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="987" width="349">Notice that there is parallelism even inside the probe phase:</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1003" width="359">looking up the key for each tuple r in a hash bucket and com-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1019" width="359">paring it to k can be parallelized with the construction of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">the output tuple, which primarily involves shuing bytes</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1050" width="359">from tuples r and s. (See Section 4.10 for an experiment</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1066" width="161">that explores this further.)</text>
=============================== COL ===================================
2 <text font="1" height="16" left="475" textpieces="1" top="83" width="188">3.4  Hash Join Variants</text>
2 <text font="3" height="13" left="489" textpieces="0" top="105" width="345">The algorithms presented above outline an interesting de-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="121" width="359">sign space for hash join algorithms. In this paper, we focus</text>
2 <text font="3" height="13" left="475" textpieces="0" top="136" width="252">on the following four hash join variations:</text>
2 <text font="3" height="13" left="491" textpieces="0" top="163" width="344">1. No partitioning join: An implementation where par-</text>
2 <text font="3" height="13" left="509" textpieces="0" top="179" width="325">titioning is omitted. This implementation creates a</text>
2 <text font="3" height="13" left="509" textpieces="0" top="195" width="223">shared hash table in the build phase.</text>
2 <text font="3" height="13" left="491" textpieces="0" top="216" width="343">2. Shared partitioning join: The rst non-blocking</text>
2 <text font="3" height="13" left="509" textpieces="0" top="232" width="325">partitioning algorithm of Section 3.1.1, where all the</text>
2 <text font="3" height="13" left="509" textpieces="0" top="247" width="325">threads partition both input sources into shared par-</text>
2 <text font="3" height="13" left="509" textpieces="0" top="263" width="325">titions. Synchronization through a latch is necessary</text>
2 <text font="3" height="13" left="509" textpieces="0" top="279" width="236">before writing to the shared partitions.</text>
2 <text font="3" height="13" left="491" textpieces="0" top="300" width="343">3. Independent partitioning join: The second non-</text>
2 <text font="3" height="13" left="509" textpieces="0" top="316" width="325">blocking partitioning algorithm of Section 3.1.1, where</text>
2 <text font="3" height="13" left="509" textpieces="0" top="332" width="325">all the threads partition both sources and create pri-</text>
2 <text font="3" height="13" left="509" textpieces="0" top="347" width="92">vate partitions.</text>
2 <text font="3" height="13" left="491" textpieces="0" top="369" width="342">4. Radix partitioning join: An implementation where</text>
2 <text font="3" height="13" left="509" textpieces="0" top="384" width="325">each input relation is stored in a single, contiguous</text>
2 <text font="3" height="13" left="509" textpieces="0" top="400" width="325">memory region. Then, each thread participates in the</text>
2 <text font="3" height="13" left="509" textpieces="0" top="416" width="290">radix partitioning, as described in Section 3.1.2.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="460" width="298">4.  EXPERIMENTAL EVALUATION</text>
2 <text font="3" height="13" left="489" textpieces="0" top="481" width="345">We have implemented the hash join algorithms described</text>
2 <text font="3" height="13" left="475" textpieces="0" top="497" width="359">in Section 3.4 in a stand-alone C++ program. The program</text>
2 <text font="3" height="13" left="475" textpieces="0" top="513" width="359">rst loads data from the disk into main memory. Data is or-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="528" width="358">ganized in memory using traditional slotted pages. The join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="544" width="359">algorithms are run after the data is loaded in memory. Since</text>
2 <text font="3" height="13" left="475" textpieces="0" top="560" width="359">the focus of this work in on memory-resident datasets, we</text>
2 <text font="3" height="13" left="475" textpieces="0" top="575" width="359">do not consider the time to load the data into main memory</text>
2 <text font="3" height="13" left="475" textpieces="0" top="591" width="233">and only report join completion times.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="607" width="345">For our workload, we wanted to simulate common and</text>
2 <text font="3" height="13" left="475" textpieces="0" top="622" width="359">expensive join operations in decision support environments.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="638" width="358">The execution of a decision support query in a data ware-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="654" width="359">house typically involves multiple phases. First, one or more</text>
2 <text font="3" height="13" left="475" textpieces="0" top="670" width="359">dimension relations are reduced based on the selection con-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="685" width="359">straints. Then, these dimension relations are combined into</text>
2 <text font="3" height="13" left="475" textpieces="0" top="701" width="358">an intermediate one, which is then joined with a much larger</text>
2 <text font="3" height="13" left="475" textpieces="0" top="717" width="359">fact relation. Finally, aggregate statistics on the join output</text>
2 <text font="3" height="13" left="475" textpieces="0" top="732" width="359">are computed and returned to the user. For example, in the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="748" width="359">TPC-H decision support benchmark, this execution pattern</text>
2 <text font="3" height="13" left="475" textpieces="0" top="764" width="278">is encountered in at least 15 of the 22 queries.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="779" width="345">We try to capture the essence of this operation by focusing</text>
2 <text font="3" height="13" left="475" textpieces="0" top="795" width="358">on the most expensive component, namely the join operation</text>
2 <text font="3" height="13" left="475" textpieces="0" top="811" width="359">between the intermediate relation R (the outcome of various</text>
2 <text font="3" height="13" left="475" textpieces="0" top="826" width="358">operations on the dimension relations) with a much larger</text>
2 <text font="3" height="13" left="475" textpieces="0" top="842" width="358">fact relation S. To allow us to focus on the core join perfor-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="858" width="358">mance, we initially do not consider the cost of materializing</text>
1 <text font="4" height="9" left="668" textpieces="0" top="897" width="91">Intel Nehalem</text>
1 <text font="4" height="12" left="555" textpieces="1" top="911" width="225">CPU              Xeon X5650 @ 2.67GHz</text>
1 <text font="4" height="12" left="553" textpieces="1" top="925" width="163">Cores                            6</text>
1 <text font="4" height="12" left="520" textpieces="1" top="939" width="196">Contexts per core                    2</text>
1 <text font="4" height="12" left="516" textpieces="1" top="953" width="245">Cache size, sharing         12MB L3, shared</text>
1 <text font="4" height="12" left="546" textpieces="1" top="968" width="208">Memory                 3x 4GB DDR3</text>
1 <text font="4" height="9" left="646" textpieces="0" top="985" width="135">Sun UltraSPARC T2</text>
1 <text font="4" height="12" left="555" textpieces="1" top="999" width="234">CPU            UltraSPARC T2 @ 1.2GHz</text>
1 <text font="4" height="12" left="553" textpieces="1" top="1013" width="163">Cores                            8</text>
1 <text font="4" height="12" left="520" textpieces="1" top="1027" width="196">Contexts per core                    8</text>
1 <text font="4" height="12" left="516" textpieces="1" top="1041" width="242">Cache size, sharing          4MB L2, shared</text>
1 <text font="4" height="12" left="546" textpieces="1" top="1056" width="208">Memory                 8x 2GB DDR2</text>
2 <text font="3" height="13" left="538" textpieces="0" top="1080" width="233">Table 1: Platform characteristics.</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="8" height="8" left="142" textpieces="0" top="263" width="5">0</text>
2 <text font="8" height="8" left="133" textpieces="0" top="232" width="14">100</text>
2 <text font="8" height="8" left="133" textpieces="0" top="202" width="14">200</text>
2 <text font="8" height="8" left="133" textpieces="0" top="172" width="14">300</text>
2 <text font="8" height="8" left="133" textpieces="0" top="142" width="14">400</text>
2 <text font="8" height="8" left="133" textpieces="0" top="111" width="14">500</text>
2 <text font="8" height="8" left="133" textpieces="0" top="81" width="14">600</text>
2 <text font="8" height="8" left="167" textpieces="0" top="269" width="0">1</text>
2 <text font="8" height="8" left="194" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="207" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="253" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="280" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="293" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="340" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="366" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="380" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="426" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="122" textpieces="0" top="211" width="0">Cycles per output tuple</text>
2 <text font="8" height="8" left="254" textpieces="0" top="324" width="73">Number of partitions</text>
2 <text font="8" height="8" left="368" textpieces="3" top="307" width="-202">Radix-best                                           Independent                                        Shared                       No</text>
2 <text font="9" height="10" left="220" textpieces="2" top="86" width="182">partition           build           probe</text>
2 <text font="3" height="13" left="220" textpieces="0" top="338" width="107">(a) Intel Nehalem</text>
2 <text font="8" height="8" left="505" textpieces="0" top="263" width="5">0</text>
2 <text font="8" height="8" left="500" textpieces="0" top="242" width="9">20</text>
2 <text font="8" height="8" left="500" textpieces="0" top="222" width="9">40</text>
2 <text font="8" height="8" left="500" textpieces="0" top="202" width="9">60</text>
2 <text font="8" height="8" left="500" textpieces="0" top="182" width="9">80</text>
2 <text font="8" height="8" left="496" textpieces="0" top="162" width="14">100</text>
2 <text font="8" height="8" left="496" textpieces="0" top="142" width="14">120</text>
2 <text font="8" height="8" left="496" textpieces="0" top="121" width="14">140</text>
2 <text font="8" height="8" left="496" textpieces="0" top="101" width="14">160</text>
2 <text font="8" height="8" left="496" textpieces="0" top="81" width="14">180</text>
2 <text font="8" height="8" left="531" textpieces="0" top="269" width="0">1</text>
2 <text font="8" height="8" left="568" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="575" textpieces="0" top="278" width="44">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="626" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="663" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="671" textpieces="0" top="278" width="22">256 512 1K 2K</text>
2 <text font="8" height="8" left="729" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="737" textpieces="0" top="278" width="44">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="788" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="485" textpieces="0" top="211" width="0">Cycles per output tuple</text>
2 <text font="8" height="8" left="617" textpieces="0" top="324" width="73">Number of partitions</text>
2 <text font="8" height="8" left="726" textpieces="3" top="307" width="-196">Radix-best                                         Independent                                      Shared                         No</text>
2 <text font="9" height="10" left="582" textpieces="2" top="86" width="183">partition            build           probe</text>
2 <text font="3" height="13" left="561" textpieces="0" top="338" width="150">(b) Sun UltraSPARC T2</text>
2 <text font="3" height="13" left="253" textpieces="0" top="361" width="408">Figure 1: Cycles per output tuple for the uniform dataset.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="391" width="359">the output in memory, adopting a similar method as pre-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="407" width="359">vious work [7, 11]. In later experiments (see Section 4.8),</text>
2 <text font="3" height="13" left="81" textpieces="0" top="423" width="359">we consider the eect of materializing the join result  in</text>
2 <text font="3" height="13" left="81" textpieces="0" top="438" width="359">these cases, the join result is created in main memory and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="454" width="117">not ushed to disk.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="470" width="345">We describe the synthetic datasets that we used in the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="485" width="359">next section (Section 4.1). In Section 4.2 we give details</text>
2 <text font="3" height="13" left="81" textpieces="0" top="501" width="359">about the hardware that we used for our experiments. We</text>
2 <text font="3" height="13" left="81" textpieces="0" top="517" width="359">continue with a presentation of the results in Sections 4.3</text>
2 <text font="3" height="13" left="81" textpieces="1" top="533" width="358">and 4.4.  We analyze the results further in Sections 4.5</text>
2 <text font="3" height="13" left="81" textpieces="0" top="548" width="359">through 4.7. We present results investigating the eect of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="564" width="359">output materialization, and the sensitivity to input sizes and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="580" width="246">selectivities in Sections 4.8 through 4.10.</text>
2 <text font="1" height="16" left="81" textpieces="1" top="608" width="98">4.1  Dataset</text>
2 <text font="3" height="13" left="94" textpieces="0" top="629" width="345">We experimented with three dierent datasets, which we</text>
2 <text font="3" height="13" left="81" textpieces="0" top="645" width="359">denote as uniform, low skew and high skew, respectively. We</text>
2 <text font="3" height="13" left="81" textpieces="0" top="661" width="359">assume that the relation R contains the primary key and the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="676" width="359">relation S contains a foreign key referencing tuples in R. In</text>
2 <text font="3" height="13" left="81" textpieces="0" top="692" width="359">all the datasets we x the cardinalities of R to 16M tuples</text>
2 <text font="3" height="13" left="81" textpieces="0" top="708" width="357">and S to 256M tuples1. We picked the ratio of R to S to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="723" width="359">be 1:16 to mimic the common decision support settings. We</text>
2 <text font="3" height="13" left="81" textpieces="0" top="739" width="282">experiment with dierent ratios in Section 4.9.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="755" width="345">In our experiments both keys and payloads are eight bytes</text>
2 <text font="3" height="13" left="81" textpieces="0" top="771" width="359">each. Each tuple is simply a &lt;key, payload&gt; pair, so tuples</text>
2 <text font="3" height="13" left="81" textpieces="0" top="786" width="359">are 16 bytes long. Keys can either be the values themselves,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="802" width="359">if the key is numeric, or an 8-byte hash of the value in the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="818" width="359">case of strings. We chose to represent payloads as 8 bytes for</text>
2 <text font="3" height="13" left="81" textpieces="0" top="833" width="359">two reasons: (a) Given that columnar storage is commonly</text>
2 <text font="3" height="13" left="81" textpieces="0" top="849" width="359">used in data warehouses, we want to simulate storing &lt;key,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="865" width="359">value&gt; or &lt;key, record-id&gt; pairs in the hash table, and (b)</text>
2 <text font="3" height="13" left="81" textpieces="0" top="880" width="358">make comparisons with existing work (i.e. [11, 4]) easier.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="896" width="359">Exploring alternative ways of constructing hash table entries</text>
2 <text font="3" height="13" left="81" textpieces="0" top="912" width="358">is not a focus of this work, but has been explored before [15].</text>
2 <text font="3" height="13" left="94" textpieces="0" top="927" width="345">For the uniform dataset, we create tuples in the relation</text>
2 <text font="3" height="12" left="81" textpieces="1" top="944" width="359">S such that each tuple matches every key in the relation R</text>
2 <text font="3" height="13" left="81" textpieces="0" top="959" width="359">with equal probability. For the skewed datasets, we added</text>
2 <text font="3" height="13" left="81" textpieces="0" top="975" width="359">skew to the distribution of the foreign keys in the relation S.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="990" width="359">(Adding skew to the relation R would violate the primary</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1006" width="359">key constraint.) We created two skewed datasets, for two</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1021" width="359">dierent s values of the Zipf distribution: low skew with</text>
2 <text font="3" height="12" left="81" textpieces="1" top="1038" width="358">s= 1.05 and high skew with s = 1.25. Intuitively, the most</text>
2 <text font="5" height="9" left="81" textpieces="2" top="1064" width="266">1Throughout the paper, M=220 and K=210.</text>
=============================== COL ===================================
2 <text font="3" height="13" left="475" textpieces="0" top="391" width="359">popular key appears in the low skew dataset 8% of the time,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="407" width="359">and the ten most popular keys account for 24% of the keys.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="423" width="359">In comparison, in the high skew dataset, the most popular</text>
2 <text font="3" height="13" left="475" textpieces="0" top="438" width="359">key appears 22% of the time, and the ten most popular keys</text>
2 <text font="3" height="13" left="475" textpieces="0" top="454" width="146">appear 52% of the time.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="470" width="345">In all the experiments, the hash buckets that are created</text>
2 <text font="3" height="13" left="475" textpieces="0" top="485" width="359">during the build phase have a xed size: they always have</text>
2 <text font="3" height="13" left="475" textpieces="0" top="501" width="359">32 bytes of space for the payload, and 8 bytes are reserved</text>
2 <text font="3" height="13" left="475" textpieces="0" top="517" width="359">for the pointer that points to the next hash bucket in case of</text>
2 <text font="3" height="13" left="475" textpieces="0" top="533" width="359">overow. These numbers were picked so that each bucket ts</text>
2 <text font="3" height="13" left="475" textpieces="0" top="548" width="359">in a single, last-level cache line for both the architectures.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="564" width="359">We size the hash table appropriately so that no overow</text>
2 <text font="3" height="13" left="475" textpieces="0" top="580" width="42">occurs.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="620" width="116">4.2  Platforms</text>
2 <text font="3" height="13" left="489" textpieces="0" top="642" width="345">We evaluated our methods on two dierent architectures:</text>
2 <text font="3" height="13" left="475" textpieces="0" top="658" width="359">the Intel Nehalem and the Sun UltraSPARC T2. We de-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="674" width="359">scribe the characteristics of each architecture in detail below,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="689" width="278">and we summarize key parameters in Table 1.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="705" width="345">The Intel Nehalem microarchitecture is the successor of</text>
2 <text font="3" height="13" left="475" textpieces="0" top="721" width="359">the Intel Core microarchitecture. All Nehalem-based CPUs</text>
2 <text font="3" height="13" left="475" textpieces="0" top="736" width="359">are superscalar processors and exploit instruction-level par-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="752" width="358">allelism by using out-of-order execution. The Nehalem fam-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="768" width="359">ily supports multi-threading, and allows two contexts to ex-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="783" width="89">ecute per core.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="799" width="345">For our experiments, we use the six-core Intel Xeon X5650</text>
2 <text font="3" height="13" left="475" textpieces="0" top="815" width="359">that was released in Q1 of 2010. This CPU has a unied</text>
2 <text font="3" height="13" left="475" textpieces="0" top="831" width="359">12MB, 16-way associative L3 cache with a line size of 64</text>
2 <text font="3" height="13" left="475" textpieces="0" top="846" width="359">bytes. This L3 cache is shared by all twelve contexts ex-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="862" width="358">ecuting on the six cores. Each core has a private 256KB,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="878" width="359">8-way associative L2 cache, with a line size of 64 bytes. Fi-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="893" width="359">nally, private 32KB instruction and data L1 caches connect</text>
2 <text font="3" height="13" left="475" textpieces="0" top="909" width="186">to each cores load/store units.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="925" width="345">The Sun UltraSPARC T2 was introduced in 2007 and re-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="940" width="360">lies heavily on multi-threading to achieve maximum through-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="956" width="359">put. An UltraSPARC T2 chip has eight cores and each core</text>
2 <text font="3" height="13" left="475" textpieces="0" top="972" width="359">has hardware support for eight contexts. UltraSPARC T2</text>
2 <text font="3" height="13" left="475" textpieces="0" top="987" width="359">does not feature out-of-order execution. Each core has a</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1003" width="359">single instruction fetch unit, a single oating point unit, a</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1019" width="359">single memory unit and two arithmetic units. At every cy-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1034" width="359">cle, each core executes at most two instructions, each taken</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1050" width="359">from two dierent contexts. Each context is scheduled in a</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1066" width="359">round-robin fashion every cycle, unless the context has ini-</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="8" height="8" left="142" textpieces="0" top="263" width="5">0</text>
2 <text font="8" height="8" left="133" textpieces="0" top="232" width="14">100</text>
2 <text font="8" height="8" left="133" textpieces="0" top="202" width="14">200</text>
2 <text font="8" height="8" left="133" textpieces="0" top="172" width="14">300</text>
2 <text font="8" height="8" left="133" textpieces="0" top="142" width="14">400</text>
2 <text font="8" height="8" left="133" textpieces="0" top="111" width="14">500</text>
2 <text font="8" height="8" left="133" textpieces="0" top="81" width="14">600</text>
2 <text font="8" height="8" left="167" textpieces="0" top="269" width="0">1</text>
2 <text font="8" height="8" left="194" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="207" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="253" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="280" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="293" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="340" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="366" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="380" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="426" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="122" textpieces="0" top="211" width="0">Cycles per output tuple</text>
2 <text font="8" height="8" left="254" textpieces="0" top="324" width="73">Number of partitions</text>
2 <text font="8" height="8" left="368" textpieces="3" top="307" width="-202">Radix-best                                           Independent                                        Shared                       No</text>
2 <text font="9" height="10" left="220" textpieces="2" top="86" width="182">partition           build           probe</text>
2 <text font="3" height="13" left="220" textpieces="0" top="338" width="107">(a) Intel Nehalem</text>
2 <text font="8" height="8" left="505" textpieces="0" top="263" width="5">0</text>
2 <text font="8" height="8" left="500" textpieces="0" top="244" width="9">50</text>
2 <text font="8" height="8" left="496" textpieces="0" top="226" width="14">100</text>
2 <text font="8" height="8" left="496" textpieces="0" top="208" width="14">150</text>
2 <text font="8" height="8" left="496" textpieces="0" top="190" width="14">200</text>
2 <text font="8" height="8" left="496" textpieces="0" top="172" width="14">250</text>
2 <text font="8" height="8" left="496" textpieces="0" top="154" width="14">300</text>
2 <text font="8" height="8" left="496" textpieces="0" top="135" width="14">350</text>
2 <text font="8" height="8" left="496" textpieces="0" top="117" width="14">400</text>
2 <text font="8" height="8" left="496" textpieces="0" top="99" width="14">450</text>
2 <text font="8" height="8" left="496" textpieces="0" top="81" width="14">500</text>
2 <text font="8" height="8" left="532" textpieces="0" top="269" width="0">1</text>
2 <text font="8" height="8" left="564" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="572" textpieces="6" top="278" width="48">256  512  1K  2K  4K  8K  32K</text>
2 <text font="8" height="8" left="628" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="660" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="668" textpieces="3" top="278" width="24">256  512  1K  2K</text>
2 <text font="8" height="8" left="724" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="732" textpieces="6" top="278" width="47">256  512  1K  2K  4K  8K  32K</text>
2 <text font="8" height="8" left="787" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="485" textpieces="0" top="211" width="0">Cycles per output tuple</text>
2 <text font="8" height="8" left="617" textpieces="0" top="324" width="73">Number of partitions</text>
2 <text font="8" height="8" left="726" textpieces="3" top="307" width="-195">Radix-best                                        Independent                                      Shared                          No</text>
2 <text font="9" height="10" left="582" textpieces="2" top="86" width="183">partition            build           probe</text>
2 <text font="3" height="13" left="561" textpieces="0" top="338" width="150">(b) Sun UltraSPARC T2</text>
2 <text font="3" height="13" left="250" textpieces="0" top="361" width="415">Figure 2: Cycles per output tuple for the low skew dataset.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="391" width="359">tiated a long-latency operation, such as a memory load that</text>
2 <text font="3" height="13" left="81" textpieces="0" top="407" width="326">caused a cache miss, and has to wait for the outcome.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="423" width="345">At the bottom of the cache hierarchy of the UltraSPARC</text>
2 <text font="3" height="13" left="81" textpieces="0" top="438" width="359">T2 chip lies a shared 4MB, 16-way associative write-back L2</text>
2 <text font="3" height="13" left="81" textpieces="0" top="454" width="359">cache, with a line size of 64 bytes. To maximize through-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="470" width="359">put, the shared cache is physically split into eight banks.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="485" width="359">Therefore, up to eight cache requests can be handled concur-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="501" width="359">rently, provided that each request hits a dierent bank. Each</text>
2 <text font="3" height="13" left="81" textpieces="0" top="517" width="359">core connects to this shared cache through a non-blocking,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="533" width="359">pipelined crossbar. Finally, each core has a 8KB, 4-way</text>
2 <text font="3" height="13" left="81" textpieces="0" top="548" width="359">associative write-through L1 data cache with 16 bytes per</text>
2 <text font="3" height="13" left="81" textpieces="0" top="564" width="359">cache line that is shared by all the eight hardware contexts.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="580" width="359">Overall, in the absence of arbitration delays, the L2 cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="595" width="140">hit latency is 20 cycles.</text>
2 <text font="1" height="16" left="81" textpieces="1" top="636" width="96">4.3  Results</text>
2 <text font="3" height="13" left="94" textpieces="0" top="658" width="345">We start with the uniform dataset. In Figure 1, we plot</text>
2 <text font="3" height="13" left="81" textpieces="0" top="674" width="359">the average number of CPU cycles that it takes to produce</text>
2 <text font="3" height="13" left="81" textpieces="0" top="689" width="359">one output tuple, without actually writing the output, for</text>
2 <text font="3" height="13" left="81" textpieces="0" top="705" width="359">a varying number of partitions. (Note that to convert the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="721" width="359">CPU cycles to wall clock time, we simply divide the CPU</text>
2 <text font="3" height="13" left="81" textpieces="0" top="736" width="359">cycles by the corresponding clock rate shown in Table 1).</text>
2 <text font="3" height="13" left="81" textpieces="0" top="752" width="359">The horizontal axis shows the dierent join algorithms (bars</text>
2 <text font="3" height="13" left="79" textpieces="0" top="768" width="360">No, Shared, Independent), corresponding to the rst</text>
2 <text font="3" height="13" left="81" textpieces="0" top="783" width="359">three hash join variants described in Section 3.4. For the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="799" width="359">radix join algorithm, we show the best result across any</text>
2 <text font="3" height="13" left="81" textpieces="0" top="815" width="359">number of passes (bars marked Radix-best). Notice that</text>
2 <text font="3" height="13" left="81" textpieces="0" top="831" width="359">we assume that the optimizer will always be correct and pick</text>
2 <text font="3" height="13" left="81" textpieces="0" top="846" width="181">the optimal number of passes.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="862" width="345">Overall, the build phase takes a very small fraction of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="878" width="359">the overall time, regardless of the partitioning strategy that</text>
2 <text font="3" height="13" left="81" textpieces="0" top="893" width="359">is being used, across all architectures (see Figure 1). The</text>
2 <text font="3" height="13" left="81" textpieces="0" top="909" width="359">reason for this behavior is two-fold. First and foremost, the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="925" width="359">smaller cardinality of the R relation translates into less work</text>
2 <text font="3" height="13" left="81" textpieces="0" top="940" width="359">during the build phase. (We experiment with dierent car-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="956" width="359">dinality ratios in Section 4.9.) Second, building a hash table</text>
2 <text font="3" height="13" left="81" textpieces="0" top="972" width="359">is a really simple operation: it merely involves copying the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="987" width="359">input data into the appropriate hash bucket, which incurs a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1003" width="359">lot less computation than the other steps, such as the out-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1019" width="359">put tuple reconstruction that must take place in the probe</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">phase. The performance of the join operation is therefore</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1050" width="359">mostly determined by the time spent partitioning the input</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1066" width="223">relations and probing the hash table.</text>
=============================== COL ===================================
2 <text font="3" height="13" left="489" textpieces="0" top="391" width="345">As can be observed in Figure 1(a) for the Intel Nehalem</text>
2 <text font="3" height="13" left="475" textpieces="0" top="407" width="358">architecture, the performance of the non-partitioned join al-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="423" width="359">gorithm is comparable to the optimal performance achieved</text>
2 <text font="3" height="13" left="475" textpieces="0" top="438" width="359">by the partition-based algorithms. The shared partitioning</text>
2 <text font="3" height="13" left="475" textpieces="0" top="454" width="359">algorithm performs best when sizing partitions so that they</text>
2 <text font="3" height="13" left="475" textpieces="0" top="470" width="358">t in the last level cache. This gure reveals a problem with</text>
2 <text font="3" height="13" left="475" textpieces="0" top="485" width="359">the independent partitioning algorithm. For a high number</text>
2 <text font="3" height="13" left="475" textpieces="0" top="501" width="359">of partitions, say 128K, each thread will create its own pri-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="517" width="359">vate buer, for a total of 128K  12  1.5 million output</text>
2 <text font="3" height="13" left="475" textpieces="0" top="533" width="359">buers. This high number of temporary buers introduces</text>
2 <text font="3" height="13" left="475" textpieces="0" top="548" width="359">two problems. First, it results in poor space utilization, as</text>
2 <text font="3" height="13" left="475" textpieces="0" top="564" width="359">most of these buers are lled with very few tuples. Sec-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="580" width="359">ond, the working set of the algorithm grows tremendously,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="595" width="359">and keeping track of 1.5 million cache lines requires a cache</text>
2 <text font="3" height="13" left="475" textpieces="0" top="611" width="358">whose capacity is orders of magnitude larger than the 12MB</text>
2 <text font="3" height="13" left="475" textpieces="0" top="627" width="359">L3 cache. The radix partitioning algorithm is not aected</text>
2 <text font="3" height="13" left="475" textpieces="0" top="642" width="359">by this problem, because it operates in multiple passes and</text>
2 <text font="3" height="13" left="475" textpieces="0" top="658" width="352">limits the number of partition output buers in each pass.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="674" width="345">Next, we experimented with the Sun UltraSPARC T2 ar-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="690" width="359">chitecture. In Figure 1(b) we see that doing no partitioning</text>
2 <text font="3" height="13" left="475" textpieces="0" top="705" width="358">is at least 1.5X faster compared to all the other algorithms.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="721" width="359">The limited memory on this machine prevented us from run-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="737" width="359">ning experiments with a high number of partitions for the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="752" width="359">independent partitioning algorithm because of the signi-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="768" width="359">cant memory overhead discussed in the previous paragraph.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="784" width="359">As this machine supports nearly ve times more hardware</text>
2 <text font="3" height="13" left="475" textpieces="0" top="799" width="359">contexts than the Intel machine, the memory that is required</text>
2 <text font="3" height="13" left="475" textpieces="0" top="815" width="263">for bookkeeping is ve times higher as well.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="831" width="345">To summarize our results with the uniform dataset, we</text>
2 <text font="3" height="13" left="475" textpieces="0" top="846" width="359">see that on the Intel architecture the performance of the no</text>
2 <text font="3" height="13" left="475" textpieces="0" top="862" width="359">partitioning join algorithm is comparable to the performance</text>
2 <text font="3" height="13" left="475" textpieces="0" top="878" width="359">of all the other algorithms. For the Sun UltraSPARC T2,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="894" width="359">we see that the no partitioning join algorithm outperforms</text>
2 <text font="3" height="13" left="475" textpieces="0" top="909" width="359">the other algorithms by at least 1.5X. Additionally, the no</text>
2 <text font="3" height="13" left="475" textpieces="0" top="925" width="359">partitioning algorithm is more robust, as the performance</text>
2 <text font="3" height="13" left="475" textpieces="0" top="940" width="359">of the other algorithms degrades if the query optimizer does</text>
2 <text font="3" height="13" left="475" textpieces="0" top="956" width="337">not pick the optimal value for the number of partitions.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="981" width="148">4.4  Effect of skew</text>
2 <text font="3" height="13" left="489" textpieces="0" top="1003" width="345">We now consider the case when the distribution of foreign</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1019" width="359">keys in the relation S is skewed. We again plot the average</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1034" width="359">time to produce each tuple of the join (in machine cycles)</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1050" width="359">in Figure 2 for the low skew dataset, and in Figure 3 for the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1066" width="111">high skew dataset.</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="8" height="8" left="142" textpieces="0" top="263" width="5">0</text>
2 <text font="8" height="8" left="133" textpieces="0" top="232" width="14">100</text>
2 <text font="8" height="8" left="133" textpieces="0" top="202" width="14">200</text>
2 <text font="8" height="8" left="133" textpieces="0" top="172" width="14">300</text>
2 <text font="8" height="8" left="133" textpieces="0" top="142" width="14">400</text>
2 <text font="8" height="8" left="133" textpieces="0" top="111" width="14">500</text>
2 <text font="8" height="8" left="133" textpieces="0" top="81" width="14">600</text>
2 <text font="8" height="8" left="167" textpieces="0" top="269" width="0">1</text>
2 <text font="8" height="8" left="194" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="207" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="253" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="280" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="293" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="340" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="366" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="380" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="426" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="122" textpieces="0" top="211" width="0">Cycles per output tuple</text>
2 <text font="8" height="8" left="254" textpieces="0" top="324" width="73">Number of partitions</text>
2 <text font="8" height="8" left="368" textpieces="3" top="307" width="-202">Radix-best                                           Independent                                        Shared                       No</text>
2 <text font="9" height="10" left="220" textpieces="2" top="86" width="182">partition           build           probe</text>
2 <text font="3" height="13" left="220" textpieces="0" top="338" width="107">(a) Intel Nehalem</text>
2 <text font="8" height="8" left="505" textpieces="0" top="263" width="5">0</text>
2 <text font="8" height="8" left="496" textpieces="0" top="237" width="14">100</text>
2 <text font="8" height="8" left="496" textpieces="0" top="211" width="14">200</text>
2 <text font="8" height="8" left="496" textpieces="0" top="185" width="14">300</text>
2 <text font="8" height="8" left="496" textpieces="0" top="159" width="14">400</text>
2 <text font="8" height="8" left="496" textpieces="0" top="133" width="14">500</text>
2 <text font="8" height="8" left="496" textpieces="0" top="107" width="14">600</text>
2 <text font="8" height="8" left="496" textpieces="0" top="81" width="14">700</text>
2 <text font="8" height="8" left="531" textpieces="0" top="269" width="0">1</text>
2 <text font="8" height="8" left="568" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="575" textpieces="0" top="278" width="44">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="626" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="663" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="671" textpieces="0" top="278" width="22">256 512 1K 2K</text>
2 <text font="8" height="8" left="729" textpieces="0" top="274" width="0">64</text>
2 <text font="8" height="8" left="737" textpieces="0" top="278" width="44">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="788" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="485" textpieces="0" top="211" width="0">Cycles per output tuple</text>
2 <text font="8" height="8" left="617" textpieces="0" top="324" width="73">Number of partitions</text>
2 <text font="8" height="8" left="726" textpieces="3" top="307" width="-196">Radix-best                                         Independent                                      Shared                         No</text>
2 <text font="9" height="10" left="582" textpieces="2" top="86" width="183">partition            build           probe</text>
2 <text font="3" height="13" left="561" textpieces="0" top="338" width="150">(b) Sun UltraSPARC T2</text>
2 <text font="3" height="13" left="246" textpieces="0" top="361" width="422">Figure 3: Cycles per output tuple for the high skew dataset.</text>
1 <text font="3" height="13" left="212" textpieces="1" top="388" width="133">Intel              Sun</text>
1 <text font="3" height="13" left="199" textpieces="1" top="404" width="184">Nehalem     UltraSPARC T2</text>
1 <text font="3" height="13" left="141" textpieces="2" top="420" width="213">NO       No / 1            No / 1</text>
1 <text font="3" height="13" left="143" textpieces="2" top="437" width="225">SN     Indep. / 16       Indep. / 64</text>
1 <text font="3" height="13" left="138" textpieces="2" top="453" width="238">L2-S   Shared / 2048    Shared / 2048</text>
1 <text font="3" height="13" left="136" textpieces="2" top="470" width="237">L2-R   Radix / 2048     Radix / 2048</text>
2 <text font="3" height="13" left="81" textpieces="0" top="501" width="359">Table 2: Shorthand notation and corresponding par-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="516" width="288">titioning strategy / number of partitions.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="564" width="345">By comparing Figure 1 with Figure 2, we notice that,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="579" width="359">when using the shared hash table (bar No in all graphs),</text>
2 <text font="3" height="13" left="81" textpieces="0" top="595" width="359">performance actually improves in the presence of skew! On</text>
2 <text font="3" height="13" left="81" textpieces="0" top="611" width="359">the other hand, the performance of the shared partitioning</text>
2 <text font="3" height="13" left="81" textpieces="0" top="627" width="359">algorithm degrades rapidly with increasing skew, while the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="642" width="359">performance of the independent partitioning and the radix</text>
2 <text font="3" height="13" left="81" textpieces="0" top="658" width="359">partitioning algorithms shows little change on the Intel Ne-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="674" width="359">halem and degrades on the Sun UltraSPARC T2. Mov-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="689" width="359">ing to Figure 3, we see that the relative performance of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="705" width="359">the non-partitioned join algorithm increases rapidly under</text>
2 <text font="3" height="13" left="81" textpieces="0" top="721" width="359">higher skew, compared to the other algorithms. The non-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="736" width="359">partitioned algorithm is generally 2X faster than the other</text>
2 <text font="3" height="13" left="81" textpieces="0" top="752" width="359">algorithms on the Intel Nehalem, and more than 4X faster</text>
2 <text font="3" height="13" left="81" textpieces="0" top="768" width="334">than the other algorithms on the Sun UltraSPARC T2.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="783" width="345">To summarize these results, skew in the underlying join</text>
2 <text font="3" height="13" left="81" textpieces="0" top="799" width="359">key values (data skew) manifests itself as partition size skew</text>
2 <text font="3" height="13" left="81" textpieces="0" top="815" width="358">when using partitioning. For the shared partitioning algo-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="831" width="359">rithm, during the partition phase, skew causes latch con-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="846" width="359">tention on the partition with the most popular key(s). For</text>
2 <text font="3" height="13" left="81" textpieces="0" top="862" width="359">all partitioning-based algorithms, during the probe phase,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="878" width="359">skew translates into a skewed work distribution per thread.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="893" width="359">Therefore, the overall join completion time is determined by</text>
2 <text font="3" height="13" left="81" textpieces="0" top="909" width="359">the completion time of the partition with the most popular</text>
2 <text font="3" height="13" left="81" textpieces="0" top="925" width="359">key. (We explore this behavior further in Section 4.7.1.) On</text>
2 <text font="3" height="13" left="81" textpieces="0" top="940" width="359">the other hand, skew improves performance when sharing</text>
2 <text font="3" height="13" left="81" textpieces="0" top="956" width="359">the hash table and not doing partitioning for two reasons.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="972" width="359">First, the no partitioning approach ensures an even work</text>
2 <text font="3" height="13" left="81" textpieces="0" top="987" width="359">distribution per thread as all the threads are working con-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1003" width="359">currently on the single partition. This greedy scheduling</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1019" width="359">strategy proves to be eective in hiding data skew. Second,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">performance increases because the hardware handles skew a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1050" width="359">lot more eciently, as skewed memory access patterns cause</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1066" width="192">signicantly fewer cache misses.</text>
=============================== COL ===================================
1 <text font="4" height="12" left="748" textpieces="1" top="388" width="69">TLB   TLB</text>
1 <text font="4" height="12" left="597" textpieces="4" top="401" width="220">Cycles     L3   Instruc-    load   store</text>
1 <text font="4" height="12" left="648" textpieces="3" top="415" width="169">miss      -tions    miss    miss</text>
1 <text font="4" height="12" left="532" textpieces="5" top="429" width="285">partition          0       0            0        0        0</text>
1 <text font="4" height="12" left="492" textpieces="6" top="442" width="325">NO         build       322       2      2,215        1        0</text>
1 <text font="4" height="12" left="549" textpieces="5" top="456" width="268">probe   15,829    862     54,762     557        0</text>
1 <text font="4" height="12" left="532" textpieces="5" top="470" width="285">partition    3,578      18     29,096        6        2</text>
1 <text font="4" height="12" left="493" textpieces="6" top="483" width="324">SN         build       328       8      2,064        0        0</text>
1 <text font="4" height="12" left="549" textpieces="5" top="497" width="268">probe   21,717    866     54,761     505        0</text>
1 <text font="4" height="12" left="532" textpieces="5" top="511" width="285">partition   11,778    103     31,117     167     257</text>
1 <text font="4" height="12" left="489" textpieces="6" top="525" width="328">L2-S        build       211       1      2,064        0        0</text>
1 <text font="4" height="12" left="549" textpieces="5" top="538" width="268">probe     6,144      35     54,762        1        0</text>
1 <text font="4" height="12" left="532" textpieces="5" top="552" width="285">partition    6,343    221     34,241        7     237</text>
1 <text font="4" height="12" left="488" textpieces="6" top="566" width="329">L2-R        build       210       1      2,064        0        0</text>
1 <text font="4" height="12" left="549" textpieces="5" top="579" width="268">probe     6,152      36     54,761        1        0</text>
2 <text font="3" height="13" left="475" textpieces="0" top="608" width="359">Table 3: Performance counter averages for the uni-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="624" width="164">form dataset (millions).</text>
2 <text font="1" height="16" left="475" textpieces="1" top="668" width="210">4.5  Performance counters</text>
2 <text font="3" height="13" left="489" textpieces="0" top="689" width="345">Due to space constraints, we focus on specic partitioning</text>
2 <text font="3" height="13" left="475" textpieces="0" top="705" width="359">congurations from this section onward. We use NO to</text>
2 <text font="3" height="13" left="475" textpieces="0" top="721" width="359">denote the no partitioning strategy where the hash table is</text>
2 <text font="3" height="13" left="475" textpieces="0" top="736" width="359">shared by all threads, and we use SN to denote the case</text>
2 <text font="3" height="13" left="475" textpieces="0" top="752" width="359">when we create as many partitions as hardware contexts</text>
2 <text font="3" height="13" left="475" textpieces="0" top="768" width="359">(join threads), except we round the number of partitions up</text>
2 <text font="3" height="13" left="475" textpieces="0" top="783" width="359">to the next power of two as is required for the radix par-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="799" width="359">titioning algorithm. We use L2 to denote the case when</text>
2 <text font="3" height="13" left="475" textpieces="0" top="815" width="359">we create partitions to t in the last level cache, appending</text>
2 <text font="3" height="13" left="474" textpieces="0" top="831" width="362">-S when partitioning with shared output buers, and -R</text>
2 <text font="3" height="13" left="475" textpieces="0" top="846" width="359">for radix partitioning. We summarize this notation in Table</text>
2 <text font="3" height="13" left="475" textpieces="0" top="862" width="359">2. Notice that the L2 numbers correspond to the best per-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="878" width="359">forming conguration settings in the experiment with the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="893" width="188">uniform dataset (see Figure 1).</text>
2 <text font="3" height="13" left="489" textpieces="0" top="909" width="345">We now use the hardware performance counters to un-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="925" width="359">derstand the characteristics of these join algorithms. In the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="940" width="359">interest of space, we only present our ndings from a single</text>
2 <text font="3" height="13" left="475" textpieces="0" top="956" width="359">architecture: the Intel Nehalem. We rst show the results</text>
2 <text font="3" height="13" left="475" textpieces="0" top="972" width="359">from the uniform dataset in Table 3. Each row indicates one</text>
2 <text font="3" height="13" left="475" textpieces="0" top="987" width="359">particular partitioning algorithm and join phase, and each</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1003" width="359">column shows a dierent architectural event. First, notice</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1019" width="358">the code path length. It takes, on average, about 55 billion</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1034" width="359">instructions to complete the probe phase and an additional</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1050" width="358">50% to 65% of that for partitioning, depending on the al-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1066" width="359">gorithm of choice. The NO algorithm pays a high cost in</text>
=============================== PAGE ===================================
=============================== COL ===================================
1 <text font="4" height="12" left="354" textpieces="1" top="82" width="69">TLB   TLB</text>
1 <text font="4" height="12" left="202" textpieces="4" top="95" width="221">Cycles     L3   Instruc-    load   store</text>
1 <text font="4" height="12" left="254" textpieces="3" top="109" width="169">miss      -tions    miss    miss</text>
1 <text font="4" height="12" left="137" textpieces="5" top="123" width="285">partition          0       0            0        0        0</text>
1 <text font="4" height="12" left="97" textpieces="6" top="136" width="325">NO         build       323       3       2,215       1        0</text>
1 <text font="4" height="12" left="154" textpieces="5" top="150" width="268">probe     6,433      98     54,762     201        0</text>
1 <text font="4" height="12" left="137" textpieces="5" top="164" width="285">partition     3,577      17     29,096        6        1</text>
1 <text font="4" height="12" left="99" textpieces="6" top="178" width="323">SN         build       329       8       2,064       0        0</text>
1 <text font="4" height="12" left="154" textpieces="5" top="191" width="268">probe   13,241      61     54,761      80        0</text>
1 <text font="4" height="12" left="137" textpieces="5" top="205" width="286">partition   36,631      79     34,941      67     106</text>
1 <text font="4" height="12" left="94" textpieces="6" top="219" width="328">L2-S        build       210       5       2,064       0        0</text>
1 <text font="4" height="12" left="154" textpieces="5" top="232" width="268">probe     8,024      13     54,762        1        0</text>
1 <text font="4" height="12" left="137" textpieces="5" top="246" width="286">partition     5,344    178     34,241        5      72</text>
1 <text font="4" height="12" left="93" textpieces="6" top="260" width="329">L2-R        build       209       4       2,064       0        0</text>
1 <text font="4" height="12" left="154" textpieces="5" top="273" width="268">probe     8,052      13     54,761        1        0</text>
2 <text font="3" height="13" left="81" textpieces="0" top="303" width="359">Table 4: Performance counter averages for the high</text>
2 <text font="3" height="13" left="81" textpieces="0" top="318" width="165">skew dataset (millions).</text>
2 <text font="3" height="13" left="81" textpieces="0" top="360" width="359">terms of the L3 cache misses during the probe phase. The</text>
2 <text font="3" height="13" left="81" textpieces="0" top="375" width="359">partitioning phase of the SN algorithm is fast but fails to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="391" width="359">contain the memory reference patterns that arise during the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="407" width="359">probe phase in the cache. The L2-S algorithm manages to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="422" width="359">minimize these memory references, but incurs a high L3 and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="438" width="359">TLB miss ratio during the partition phase compared to the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="454" width="359">NO and SN algorithms. The L2-R algorithm uses multiple</text>
2 <text font="3" height="13" left="81" textpieces="0" top="470" width="359">passes to partition the input and carefully controls the L3</text>
2 <text font="3" height="13" left="81" textpieces="0" top="485" width="359">and TLB misses during these phases. Once the cache-sized</text>
2 <text font="3" height="13" left="81" textpieces="0" top="501" width="359">partitions have been created, we see that both the L2-S and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="517" width="359">L2-R algorithms avoid incurring many L3 and TLB misses</text>
2 <text font="3" height="13" left="81" textpieces="0" top="532" width="359">during the probe phase. In general, we see fewer cache and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="548" width="359">TLB misses across all algorithms when adding skew (in Ta-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="564" width="38">ble 4).</text>
2 <text font="3" height="13" left="94" textpieces="0" top="579" width="345">Unfortunately, interpreting performance counters is much</text>
2 <text font="3" height="13" left="81" textpieces="0" top="595" width="359">more challenging with modern multi-core processors and will</text>
2 <text font="3" height="13" left="81" textpieces="0" top="611" width="359">likely get worse. Processors have become a lot more com-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="627" width="359">plex over the last ten years, yet the events that counters</text>
2 <text font="3" height="13" left="81" textpieces="0" top="642" width="358">capture have hardly changed. This trend causes a grow-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="658" width="359">ing gap between the high-level algorithmic insights the user</text>
2 <text font="3" height="13" left="81" textpieces="0" top="674" width="359">expects and the specic causes that trigger some proces-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="689" width="359">sor state that the performance counters can capture. In a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="705" width="359">uniprocessor, for example, a cache miss is an indication that</text>
2 <text font="3" height="13" left="81" textpieces="0" top="721" width="359">the working set exceeds the caches capacity. The penalty</text>
2 <text font="3" height="13" left="81" textpieces="0" top="736" width="359">is bringing the data from memory, an operation the costs</text>
2 <text font="3" height="13" left="81" textpieces="0" top="752" width="359">hundreds of cycles. However, in a multi-core processor, a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="768" width="358">memory load might miss in the cache because the operation</text>
2 <text font="3" height="13" left="81" textpieces="0" top="783" width="359">touches memory that some other core has just modied. The</text>
2 <text font="3" height="13" left="81" textpieces="0" top="799" width="359">penalty in this case is looking in some other cache for the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="815" width="359">data. Although a neighboring cache lookup can be ten or a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="831" width="359">hundred times faster than bringing the data from memory,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="846" width="359">both scenarios will simply increment the cache miss counter</text>
2 <text font="3" height="13" left="81" textpieces="0" top="862" width="233">and not record the cause of this event.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="878" width="345">To illustrate this point, lets turn our attention to a case in</text>
2 <text font="3" height="13" left="81" textpieces="0" top="893" width="359">Table 3 where the performance counter results can be mis-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="909" width="359">leading: The probe phase of the SN algorithm has slightly</text>
2 <text font="3" height="13" left="81" textpieces="0" top="925" width="359">fewer L3 and TLB misses than the probe phase of the NO</text>
2 <text font="3" height="13" left="81" textpieces="0" top="940" width="359">algorithm and equal path length, so the probe phase of the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="956" width="359">SN algorithm should be comparable or faster than probe</text>
2 <text font="3" height="13" left="81" textpieces="0" top="972" width="359">phase of the NO algorithm. However, the probe phase of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="987" width="359">the NO algorithm is almost 25% faster! Another issue is</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1003" width="359">latch contention, which causes neither L3 cache misses nor</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1019" width="359">TLB misses, and therefore is not reported in the perfor-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">mance counters. For example, when comparing the uniform</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1050" width="359">and high skew numbers for the L2-S algorithm, the number</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1066" width="359">of the L3 cache misses during the high skew experiment is</text>
=============================== COL ===================================
2 <text font="8" height="8" left="549" textpieces="0" top="300" width="5">0</text>
2 <text font="8" height="8" left="549" textpieces="0" top="264" width="5">2</text>
2 <text font="8" height="8" left="549" textpieces="0" top="227" width="5">4</text>
2 <text font="8" height="8" left="549" textpieces="0" top="191" width="5">6</text>
2 <text font="8" height="8" left="549" textpieces="0" top="154" width="5">8</text>
2 <text font="8" height="8" left="544" textpieces="0" top="118" width="9">10</text>
2 <text font="8" height="8" left="544" textpieces="0" top="81" width="9">12</text>
2 <text font="8" height="8" left="556" textpieces="6" top="310" width="225">0          2          4          6          8         10         12</text>
2 <text font="8" height="8" left="533" textpieces="0" top="205" width="0">Speedup</text>
2 <text font="8" height="8" left="634" textpieces="0" top="325" width="67">Number of threads</text>
2 <text font="8" height="8" left="568" textpieces="0" top="91" width="12">NO</text>
2 <text font="8" height="8" left="569" textpieces="0" top="101" width="11">SN</text>
2 <text font="8" height="8" left="563" textpieces="0" top="110" width="17">L2-S</text>
2 <text font="8" height="8" left="563" textpieces="0" top="120" width="18">L2-R</text>
2 <text font="3" height="13" left="475" textpieces="0" top="352" width="359">Figure 4: Speedup over single threaded execution,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="367" width="115">uniform dataset.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="409" width="359">30% lower than the number of the cache misses observed</text>
2 <text font="3" height="13" left="475" textpieces="0" top="425" width="359">during the uniform experiment. However, partitioning per-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="440" width="359">formance worsens by more than 3X when creating shared</text>
2 <text font="3" height="13" left="475" textpieces="0" top="456" width="165">partitions under high skew!</text>
2 <text font="3" height="13" left="489" textpieces="0" top="472" width="345">The performance counters dont provide clean insights</text>
2 <text font="3" height="13" left="475" textpieces="0" top="487" width="359">into why the non-partitioned algorithm exhibits similar or</text>
2 <text font="3" height="13" left="475" textpieces="0" top="503" width="358">better performance than the other cache-ecient algorithms</text>
2 <text font="3" height="13" left="475" textpieces="0" top="519" width="358">across all datasets. Although a cycle breakdown is still fea-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="534" width="359">sible at a macroscopic level where the assumption of no con-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="550" width="359">tention holds (for example as in Ailamaki et al. [1]), this ex-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="566" width="359">periment reveals that blindly assigning xed cycle penalties</text>
2 <text font="3" height="13" left="475" textpieces="0" top="582" width="351">to architectural events can lead to misleading conclusions.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="620" width="192">4.6  Speedup from SMT</text>
2 <text font="3" height="13" left="489" textpieces="0" top="642" width="350">Modern processors improve the overall eciency with hard-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="658" width="359">ware multithreading. Simultaneous multi-threading (SMT)</text>
2 <text font="3" height="13" left="475" textpieces="0" top="674" width="359">permits multiple independent threads of execution to better</text>
2 <text font="3" height="13" left="475" textpieces="0" top="689" width="359">utilize the resources provided by modern processor architec-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="705" width="358">tures. We now evaluate the impact of SMT on the hash join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="721" width="67">algorithms.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="736" width="345">We rst show a speedup experiment for the Intel Nehalem</text>
2 <text font="3" height="13" left="475" textpieces="0" top="752" width="359">on the uniform dataset in Figure 4. We start by dedicating</text>
2 <text font="3" height="13" left="475" textpieces="0" top="768" width="359">each thread to a core, and once we exceed the number of</text>
2 <text font="3" height="13" left="475" textpieces="0" top="783" width="359">available physical cores (six for our Intel Nehalem), we then</text>
2 <text font="3" height="13" left="475" textpieces="0" top="799" width="359">start assigning threads in a round-robin fashion to the avail-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="815" width="359">able hardware contexts. We observe that the algorithms be-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="831" width="359">have very dierently when some cores are idle (fewer than six</text>
2 <text font="3" height="13" left="475" textpieces="0" top="846" width="359">threads) versus in the SMT region (more than six threads).</text>
2 <text font="3" height="13" left="475" textpieces="0" top="862" width="359">With fewer than six threads all the algorithms scale linearly,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="878" width="359">and the NO algorithm has optimal speedup. With more</text>
2 <text font="3" height="13" left="475" textpieces="0" top="893" width="359">than six threads, the NO algorithm continues to scale, be-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="909" width="359">coming almost 11X faster than the single-threaded version</text>
2 <text font="3" height="13" left="475" textpieces="0" top="925" width="359">when using all available contexts. The partitioning-based</text>
2 <text font="3" height="13" left="475" textpieces="0" top="940" width="359">algorithms SN, L2-S and L2-R, however, do not exhibit this</text>
2 <text font="3" height="13" left="475" textpieces="0" top="956" width="359">behavior. The speedup curve for these three algorithms in</text>
2 <text font="3" height="13" left="475" textpieces="0" top="972" width="359">the SMT region either attens completely (SN algorithm), or</text>
2 <text font="3" height="13" left="475" textpieces="0" top="987" width="359">increases at a reduced rate (L2-R algorithm) than the non-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1003" width="359">SMT region. In fact, performance drops for all partitioning</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1019" width="359">algorithms for seven threads because of load imbalance: a</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1034" width="359">single core has to do the work for two threads. (This imbal-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1050" width="359">ance can be ameliorated through load balancing, a technique</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1066" width="200">that we explore in Section 4.7.1.)</text>
=============================== PAGE ===================================
=============================== COL ===================================
1 <text font="3" height="13" left="205" textpieces="0" top="82" width="58">Uniform</text>
1 <text font="3" height="13" left="167" textpieces="2" top="98" width="234">6 threads  12 threads   Improvement</text>
1 <text font="3" height="13" left="125" textpieces="3" top="114" width="253">NO      28.23        16.15          1.75X</text>
1 <text font="3" height="13" left="126" textpieces="3" top="131" width="252">SN      34.04        25.62          1.33X</text>
1 <text font="3" height="13" left="121" textpieces="3" top="147" width="257">L2-S     19.27        18.13          1.06X</text>
1 <text font="3" height="13" left="120" textpieces="3" top="164" width="258">L2-R     14.46        12.71          1.14X</text>
1 <text font="3" height="13" left="198" textpieces="0" top="183" width="72">High skew</text>
1 <text font="3" height="13" left="167" textpieces="2" top="199" width="234">6 threads  12 threads   Improvement</text>
1 <text font="3" height="13" left="125" textpieces="3" top="215" width="253">NO      9.34         6.76           1.38X</text>
1 <text font="3" height="13" left="126" textpieces="3" top="231" width="252">SN      19.50        17.15          1.14X</text>
1 <text font="3" height="13" left="121" textpieces="3" top="248" width="257">L2-S     38.37        44.87          0.86X</text>
1 <text font="3" height="13" left="120" textpieces="3" top="264" width="258">L2-R     15.04        13.61          1.11X</text>
2 <text font="3" height="13" left="81" textpieces="0" top="296" width="359">Table 5: Simultaneous multi-threading experiment</text>
2 <text font="3" height="13" left="81" textpieces="0" top="311" width="359">on the Intel Nehalem, showing billions of cycles to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="327" width="297">join completion and relative improvement.</text>
1 <text font="3" height="13" left="205" textpieces="0" top="370" width="58">Uniform</text>
1 <text font="3" height="13" left="167" textpieces="2" top="386" width="234">8 threads  64 threads   Improvement</text>
1 <text font="3" height="13" left="125" textpieces="3" top="402" width="253">NO      37.30        12.64          2.95X</text>
1 <text font="3" height="13" left="126" textpieces="3" top="419" width="252">SN      55.70        22.25          2.50X</text>
1 <text font="3" height="13" left="121" textpieces="3" top="435" width="257">L2-S     51.62        23.86          2.16X</text>
1 <text font="3" height="13" left="120" textpieces="3" top="452" width="258">L2-R     46.62        18.88          2.47X</text>
1 <text font="3" height="13" left="198" textpieces="0" top="471" width="72">High skew</text>
1 <text font="3" height="13" left="167" textpieces="2" top="487" width="234">8 threads  64 threads   Improvement</text>
1 <text font="3" height="13" left="125" textpieces="3" top="503" width="253">NO      23.92        11.67          2.05X</text>
1 <text font="3" height="13" left="126" textpieces="3" top="519" width="252">SN      70.52        49.54          1.42X</text>
1 <text font="3" height="13" left="121" textpieces="3" top="536" width="257">L2-S     73.91       221.01         0.33X</text>
1 <text font="3" height="13" left="120" textpieces="3" top="552" width="258">L2-R     66.01        43.16          1.53X</text>
2 <text font="3" height="13" left="81" textpieces="0" top="583" width="359">Table 6: Simultaneous multi-threading experiment</text>
2 <text font="3" height="13" left="81" textpieces="0" top="599" width="359">on the Sun UltraSPARC T2, showing billions of cy-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="615" width="346">cles to join completion and relative improvement.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="658" width="345">We summarize the benet of SMT in Table 5 for the In-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="674" width="359">tel architecture, and in Table 6 for the Sun architecture.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="689" width="359">For the Intel Nehalem and the uniform dataset, the NO al-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="705" width="358">gorithm benets signicantly from SMT, becoming 1.75X</text>
2 <text font="3" height="13" left="81" textpieces="0" top="721" width="359">faster. This algorithm is not optimized for cache perfor-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="736" width="358">mance, and as seen in Section 4.5, causes many cache misses.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="752" width="359">As a result, it provides more opportunities for SMT to ef-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="768" width="359">ciently overlap the memory accesses. On the other hand,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="783" width="359">the other three algorithms are optimized for cache perfor-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="799" width="359">mance to dierent degrees. Their computation is a large</text>
2 <text font="3" height="13" left="81" textpieces="0" top="815" width="359">fraction of the total execution time, therefore they do not</text>
2 <text font="3" height="13" left="81" textpieces="0" top="831" width="359">benet signicantly from using SMT. In addition, we notice</text>
2 <text font="3" height="13" left="81" textpieces="0" top="846" width="359">that the NO algorithm is around 2X slower than the L2-R</text>
2 <text font="3" height="13" left="81" textpieces="0" top="862" width="359">algorithm without SMT, but its performance increases to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="878" width="353">almost match the L2-R algorithm performance with SMT.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="893" width="345">For the Sun UltraSPARC T2, the NO algorithm also ben-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="909" width="359">ets the most from SMT. In this architecture the code path</text>
2 <text font="3" height="13" left="81" textpieces="0" top="925" width="359">length (i.e. instructions executed) has a direct impact on the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="940" width="359">join completion time, and therefore the NO algorithm per-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="956" width="359">forms best both with and without SMT. As the Sun machine</text>
2 <text font="3" height="13" left="81" textpieces="0" top="972" width="358">cannot exploit instruction parallelism at all, we see increased</text>
2 <text font="3" height="13" left="81" textpieces="0" top="987" width="330">benets from SMT compared to the Intel architecture.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="1003" width="345">When comparing the high skew dataset with the uniform</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1019" width="359">dataset across both architectures, we see that the improve-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">ment of SMT is reduced. The skewed key distribution in-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1050" width="359">curs fewer cache misses, therefore SMT loses opportunities</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1066" width="193">to hide processor pipeline stalls.</text>
=============================== COL ===================================
2 <text font="1" height="16" left="475" textpieces="1" top="83" width="166">4.7  Synchronization</text>
2 <text font="3" height="13" left="489" textpieces="0" top="105" width="350">Synchronization is used in multithreaded programs to guar-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="121" width="358">antee the consistency of shared data structures. In our join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="136" width="359">implementations, we use barrier synchronization when all</text>
2 <text font="3" height="13" left="475" textpieces="0" top="152" width="359">the threads wait for tasks to be completed before they can</text>
2 <text font="3" height="13" left="475" textpieces="0" top="168" width="359">proceed to the next task. (For example, at the end of each</text>
2 <text font="3" height="13" left="475" textpieces="0" top="183" width="359">pass of the radix partition phase, each thread has to wait</text>
2 <text font="3" height="13" left="475" textpieces="0" top="199" width="359">until all other threads complete before proceeding.) In this</text>
2 <text font="3" height="13" left="475" textpieces="0" top="215" width="359">section, we study the eect of barrier synchronization on</text>
2 <text font="3" height="13" left="475" textpieces="0" top="231" width="359">the performance of the hash join algorithm. In the interest</text>
2 <text font="3" height="13" left="475" textpieces="0" top="246" width="359">of space, we only present results for the Intel Nehalem ma-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="262" width="359">chine. Since the radix partitioning algorithm wins over the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="278" width="359">other partitioning algorithms across all datasets, our discus-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="293" width="359">sion only focuses on results for the non-partitioned algorithm</text>
2 <text font="3" height="13" left="475" textpieces="0" top="309" width="307">(NO) and the radix partitioning algorithm (L2-R).</text>
2 <text font="3" height="13" left="489" textpieces="0" top="325" width="345">Synchronization has little impact on the non-partitioned</text>
2 <text font="3" height="13" left="475" textpieces="0" top="340" width="359">(NO) algorithm for both the uniform and the high skew</text>
2 <text font="3" height="13" left="475" textpieces="0" top="356" width="359">datasets, regardless of the number of threads that are run-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="372" width="359">ning. The reason for this behavior is the simplicity of the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="387" width="359">NO algorithm. First, there is no partition phase at all, and</text>
2 <text font="3" height="13" left="475" textpieces="0" top="403" width="359">each thread can proceed independently in the probe phase.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="419" width="359">Therefore synchronization is only necessary during the build</text>
2 <text font="3" height="13" left="475" textpieces="0" top="435" width="359">phase, a phase that takes less than 2% of the total time (see</text>
2 <text font="3" height="13" left="475" textpieces="0" top="450" width="359">Figure 1). Second, by dispensing with partitioning, this</text>
2 <text font="3" height="13" left="475" textpieces="0" top="466" width="359">algorithm ensures an even distribution of work across the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="481" width="359">threads, as all the threads are working concurrently on the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="497" width="148">single shared hash table.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="513" width="345">We now turn our attention to the radix partitioning al-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="529" width="359">gorithm, and break down the time spent by each thread.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="544" width="359">Unlike the non-partitioned algorithm, the radix partitioning</text>
2 <text font="3" height="13" left="475" textpieces="0" top="560" width="359">algorithm is signicantly impacted by synchronization on</text>
2 <text font="3" height="13" left="475" textpieces="0" top="576" width="359">both the uniform and the high skew datasets. Figure 5(a)</text>
2 <text font="3" height="13" left="475" textpieces="0" top="591" width="359">shows the time breakdown for the L2-R algorithm when run-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="607" width="359">ning 12 threads on the Intel Nehalem machine with the high</text>
2 <text font="3" height="13" left="475" textpieces="0" top="623" width="359">skew dataset. Each histogram in this gure represents the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="638" width="359">execution ow of a thread. The vertical axis can be viewed</text>
2 <text font="3" height="13" left="475" textpieces="0" top="654" width="359">as a time axis (in machine cycles). White rectangles in these</text>
2 <text font="3" height="13" left="475" textpieces="0" top="670" width="359">histograms represent tasks, the position of each rectangle in-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="686" width="359">dicates the beginning time of the task, and the height repre-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="701" width="359">sents the completion time of this task for each thread. The</text>
2 <text font="3" height="13" left="475" textpieces="0" top="717" width="359">gray rectangles represent the waiting time that is incurred</text>
2 <text font="3" height="13" left="475" textpieces="0" top="733" width="359">by a thread that completes its task but needs to synchro-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="748" width="359">nize with the other threads before continuing. In the radix</text>
2 <text font="3" height="13" left="475" textpieces="0" top="764" width="359">join algorithm, we can see ve expensive operations that are</text>
2 <text font="3" height="13" left="475" textpieces="0" top="780" width="359">synchronized through barriers: (1) computing the thread-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="795" width="359">private histogram, (2) computing the global histogram, (3)</text>
2 <text font="3" height="13" left="475" textpieces="0" top="811" width="359">doing radix partitioning, (4) building a hash table for each</text>
2 <text font="3" height="13" left="475" textpieces="0" top="827" width="359">partition of the relation R, and (5) probing each hash table</text>
2 <text font="3" height="13" left="475" textpieces="0" top="842" width="359">with a partition from the relation S. The synchronization</text>
2 <text font="3" height="13" left="475" textpieces="0" top="858" width="359">cost of the radix partitioning algorithm accounts for nearly</text>
2 <text font="3" height="13" left="475" textpieces="0" top="874" width="333">half of the total join completion time for some threads.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="890" width="345">The synchronization cost is so high under skew primar-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="905" width="359">ily because it is hard to statically divide work items into</text>
2 <text font="3" height="13" left="475" textpieces="0" top="921" width="359">equally-sized subtasks. As a result, faster threads have to</text>
2 <text font="3" height="13" left="475" textpieces="0" top="937" width="359">wait for slower threads. For example, if threads are stat-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="952" width="359">ically assigned to work on partitions in the probe phase,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="968" width="359">the distribution of the work assigned to the threads will in-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="984" width="359">variably also be skewed. Thus, the thread processing the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="999" width="359">partition with the most popular key becomes a bottleneck</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1015" width="359">and the overall completion time is determined by the com-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1031" width="359">pletion time of the partition with the most popular keys. In</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1047" width="172">Figure 5(a), this is thread 3.</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="8" height="8" left="142" textpieces="0" top="311" width="5">0</text>
2 <text font="8" height="8" left="142" textpieces="0" top="282" width="5">2</text>
2 <text font="8" height="8" left="142" textpieces="0" top="253" width="5">4</text>
2 <text font="8" height="8" left="142" textpieces="0" top="223" width="5">6</text>
2 <text font="8" height="8" left="142" textpieces="0" top="194" width="5">8</text>
2 <text font="8" height="8" left="138" textpieces="0" top="165" width="9">10</text>
2 <text font="8" height="8" left="138" textpieces="0" top="136" width="9">12</text>
2 <text font="8" height="8" left="138" textpieces="0" top="107" width="9">14</text>
2 <text font="8" height="8" left="171" textpieces="11" top="321" width="243">1     2     3     4     5     6     7     8     9    10    11    12</text>
2 <text font="8" height="8" left="127" textpieces="0" top="228" width="0">Cycles (billions)</text>
2 <text font="8" height="8" left="273" textpieces="0" top="335" width="36">Thread ID</text>
2 <text font="9" height="10" left="225" textpieces="1" top="81" width="102">work               wait</text>
2 <text font="3" height="13" left="210" textpieces="0" top="348" width="132">(a) High skew dataset</text>
2 <text font="8" height="8" left="500" textpieces="0" top="311" width="5">0</text>
2 <text font="8" height="8" left="500" textpieces="0" top="282" width="5">2</text>
2 <text font="8" height="8" left="500" textpieces="0" top="253" width="5">4</text>
2 <text font="8" height="8" left="500" textpieces="0" top="223" width="5">6</text>
2 <text font="8" height="8" left="500" textpieces="0" top="194" width="5">8</text>
2 <text font="8" height="8" left="496" textpieces="0" top="165" width="9">10</text>
2 <text font="8" height="8" left="496" textpieces="0" top="136" width="9">12</text>
2 <text font="8" height="8" left="496" textpieces="0" top="107" width="9">14</text>
2 <text font="8" height="8" left="529" textpieces="11" top="321" width="242">1     2     3     4     5     6     7     8     9     10    11    12</text>
2 <text font="8" height="8" left="484" textpieces="0" top="228" width="0">Cycles (billions)</text>
2 <text font="8" height="8" left="631" textpieces="0" top="335" width="36">Thread ID</text>
2 <text font="9" height="10" left="583" textpieces="1" top="81" width="102">work               wait</text>
2 <text font="3" height="13" left="509" textpieces="0" top="348" width="249">(b) High skew dataset with work stealing</text>
2 <text font="3" height="13" left="303" textpieces="0" top="370" width="309">Figure 5: Time breakdown of the radix join.</text>
2 <text font="7" height="15" left="85" textpieces="1" top="400" width="153">4.7.1  Load balancing</text>
2 <text font="3" height="13" left="94" textpieces="0" top="420" width="345">If static work allocation is the problem, then how would</text>
2 <text font="3" height="13" left="81" textpieces="0" top="436" width="359">the radix join algorithm perform under a dynamic work al-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="452" width="359">location policy and highly skewed input? To answer this</text>
2 <text font="3" height="13" left="81" textpieces="0" top="467" width="359">question, we tweaked the join algorithm to allow the faster</text>
2 <text font="3" height="13" left="81" textpieces="0" top="483" width="359">threads that have completed their probe phase to steal work</text>
2 <text font="3" height="13" left="81" textpieces="0" top="499" width="359">from other slower threads. In our implementation, the unit</text>
2 <text font="3" height="13" left="81" textpieces="0" top="514" width="359">of work is a single partition. In doing so, we slightly increase</text>
2 <text font="3" height="13" left="81" textpieces="0" top="530" width="359">the synchronization cost because work queues need to now</text>
2 <text font="3" height="13" left="81" textpieces="0" top="546" width="351">be protected with latches, but we balance the load better.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="561" width="345">In Figure 5(b) we plot the breakdown of the radix par-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="577" width="359">titioning algorithm (L2-R) using this work stealing policy</text>
2 <text font="3" height="13" left="81" textpieces="0" top="593" width="359">when running on the Intel Nehalem machine with the high</text>
2 <text font="3" height="13" left="81" textpieces="0" top="609" width="359">skew dataset. Although the work is now balanced almost</text>
2 <text font="3" height="13" left="81" textpieces="0" top="624" width="359">perfectly for the smaller partitions, the partitions with the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="640" width="359">most popular keys are still a bottleneck. In the high skew</text>
2 <text font="3" height="13" left="81" textpieces="0" top="656" width="359">dataset, the most popular key appears 22% of the time, and</text>
2 <text font="3" height="13" left="81" textpieces="0" top="671" width="359">thread 3 in this case has been assigned only a single par-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="687" width="359">tition which happened to correspond to the most popular</text>
2 <text font="3" height="13" left="81" textpieces="0" top="703" width="359">key. In comparison, for this particular experiment, the NO</text>
2 <text font="3" height="13" left="81" textpieces="0" top="718" width="359">algorithm can complete the join in under 7 billion cycles</text>
2 <text font="3" height="13" left="81" textpieces="0" top="734" width="359">(Table 4), and hence is 1.9X faster. An interesting area for</text>
2 <text font="3" height="13" left="81" textpieces="0" top="750" width="359">future work is load balancing techniques that permit work</text>
2 <text font="3" height="13" left="81" textpieces="0" top="766" width="359">stealing at a ner granularity than an entire partition with</text>
2 <text font="3" height="13" left="81" textpieces="0" top="781" width="206">a reasonable synchronization cost.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="797" width="345">To summarize, under skew, a load balancing technique</text>
2 <text font="3" height="13" left="81" textpieces="0" top="813" width="359">improves the performance of the probe phase but does not</text>
2 <text font="3" height="13" left="81" textpieces="0" top="828" width="359">address the inherent ineciency of all the partitioning-based</text>
2 <text font="3" height="13" left="81" textpieces="0" top="844" width="359">algorithms. In essence, there is a coordination cost to be</text>
2 <text font="3" height="13" left="81" textpieces="0" top="860" width="359">paid for load balancing, as thread synchronization is neces-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="875" width="359">sary. Skew in this case causes contention, stressing the cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="891" width="359">coherence protocol and increasing memory trac. On the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="907" width="359">other hand, the no partitioning algorithm does skewed mem-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="922" width="359">ory loads of read-only data, which is handled very eciently</text>
2 <text font="3" height="13" left="81" textpieces="0" top="938" width="210">by modern CPUs through caching.</text>
2 <text font="1" height="16" left="81" textpieces="1" top="981" width="282">4.8  Effect of output materialization</text>
2 <text font="3" height="13" left="94" textpieces="0" top="1003" width="345">Early work in main memory join processing [7] did not</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1019" width="358">take into account the cost of materialization. This decision</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">was justied by pointing out that materialization comes at a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1050" width="359">xed price for all algorithms and, therefore, a join algorithm</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1066" width="359">will be faster regardless of the output being materialized or</text>
=============================== COL ===================================
1 <text font="3" height="13" left="534" textpieces="4" top="398" width="275">Machine         NO   SN   L2-S  L2-R</text>
1 <text font="3" height="13" left="521" textpieces="4" top="414" width="283">Intel Nehalem      23%   4%    7%     10%</text>
1 <text font="3" height="13" left="500" textpieces="4" top="431" width="304">Sun UltraSPARC T2   29%  21%   20%    23%</text>
2 <text font="3" height="13" left="475" textpieces="0" top="462" width="359">Table 7: Additional overhead of materialization with</text>
2 <text font="3" height="13" left="475" textpieces="0" top="477" width="359">respect to total cycles without materialization on</text>
2 <text font="3" height="13" left="475" textpieces="0" top="493" width="142">the uniform dataset.</text>
1 <text font="3" height="13" left="550" textpieces="2" top="510" width="252">Scale 0.5        Scale 1        Scale 2</text>
1 <text font="3" height="13" left="495" textpieces="3" top="526" width="324">NO     7.65 (0.47X)  16.15 (1.00X)  62.27 (3.86X)</text>
1 <text font="3" height="13" left="497" textpieces="3" top="543" width="322">SN    11.76 (0.46X)  25.62 (1.00X)  98.82 (3.86X)</text>
1 <text font="3" height="13" left="492" textpieces="3" top="559" width="327">L2-S     8.47 (0.47X)  18.13 (1.00X)  68.48 (3.78X)</text>
1 <text font="3" height="13" left="490" textpieces="3" top="575" width="303">L2-R     5.82 (0.46X)  12.71 (1.00X)       DNF</text>
2 <text font="3" height="13" left="475" textpieces="0" top="606" width="359">Table 8: Join sensitivity with varying input cardi-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="622" width="359">nalities for the uniform dataset on Intel Nehalem.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="638" width="359">The table shows the cycles for computing the join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="654" width="343">(in billions) and the relative dierence to scale 1.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="687" width="359">discarded. Recent work by Cieslewicz et al. [3] highlighted</text>
2 <text font="3" height="13" left="475" textpieces="0" top="703" width="326">the trade-os involved when materializing the output.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="719" width="345">In Table 7 we report the increase in the total join comple-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="734" width="359">tion time when we materialize the output in memory for the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="750" width="359">uniform dataset and the partitioning strategies described in</text>
2 <text font="3" height="13" left="475" textpieces="0" top="766" width="359">Table 2. If the join operator is part of a complex query</text>
2 <text font="3" height="13" left="475" textpieces="0" top="781" width="359">plan, it is unlikely that the entire join output will ever need</text>
2 <text font="3" height="13" left="475" textpieces="0" top="797" width="359">to be written in one big memory block, but, even in this</text>
2 <text font="3" height="13" left="475" textpieces="0" top="813" width="359">extreme case, we see that no algorithm is being signicantly</text>
2 <text font="3" height="13" left="475" textpieces="0" top="828" width="173">impacted by materialization.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="856" width="228">4.9  Cardinality experiments</text>
2 <text font="3" height="13" left="489" textpieces="0" top="878" width="345">We now explore how sensitive our ndings are to varia-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="893" width="359">tions in the cardinalities of the two input relations. Table 8</text>
2 <text font="3" height="13" left="475" textpieces="0" top="909" width="359">shows the results when running the join algorithms on the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="925" width="359">Intel Nehalem machine. The numbers obtained from the uni-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="940" width="359">form dataset (described in detail in Section 4.1) are shown</text>
2 <text font="3" height="13" left="475" textpieces="0" top="956" width="359">in the middle column. We rst created one uniform dataset</text>
2 <text font="3" height="13" left="475" textpieces="0" top="972" width="359">where both relations are half the size (scale 0.5). This means</text>
2 <text font="3" height="13" left="475" textpieces="0" top="987" width="359">the relation R has 8M tuples and the relation S has 128M tu-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1003" width="359">ples. We also created a uniform dataset where both relations</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1019" width="359">are twice the size (scale 2), i.e. the relation R has 32M tu-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1034" width="359">ples and the relation S has 512M tuples. The scale 2 dataset</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1050" width="359">occupies 9GB out of the 12GB of memory our system has</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1066" width="358">(Table 1) and leaves little working memory, but the serial</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="8" height="8" left="129" textpieces="0" top="263" width="5">0</text>
2 <text font="8" height="8" left="120" textpieces="0" top="240" width="14">100</text>
2 <text font="8" height="8" left="120" textpieces="0" top="217" width="14">200</text>
2 <text font="8" height="8" left="120" textpieces="0" top="194" width="14">300</text>
2 <text font="8" height="8" left="120" textpieces="0" top="172" width="14">400</text>
2 <text font="8" height="8" left="120" textpieces="0" top="149" width="14">500</text>
2 <text font="8" height="8" left="120" textpieces="0" top="126" width="14">600</text>
2 <text font="8" height="8" left="120" textpieces="0" top="104" width="14">700</text>
2 <text font="8" height="8" left="120" textpieces="0" top="81" width="14">800</text>
2 <text font="8" height="8" left="153" textpieces="0" top="269" width="0">1</text>
2 <text font="8" height="8" left="180" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="193" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="240" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="266" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="280" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="326" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="353" textpieces="0" top="274" width="7">16 64</text>
2 <text font="8" height="8" left="366" textpieces="0" top="278" width="40">256 512 1K 2K 4K 8K 32K</text>
2 <text font="8" height="8" left="412" textpieces="0" top="284" width="0">128K</text>
2 <text font="8" height="8" left="108" textpieces="0" top="211" width="0">Cycles per output tuple</text>
2 <text font="8" height="8" left="241" textpieces="0" top="324" width="73">Number of partitions</text>
2 <text font="8" height="8" left="354" textpieces="3" top="307" width="-202">Radix-best                                          Independent                                        Shared                        No</text>
2 <text font="9" height="10" left="206" textpieces="2" top="86" width="183">partition            build           probe</text>
2 <text font="3" height="13" left="81" textpieces="0" top="353" width="359">Figure 6: Experiment on Intel Nehalem with uni-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="369" width="179">form dataset and |R|=|S|.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="403" width="359">access pattern allows performance to degrade gracefully for</text>
2 <text font="3" height="13" left="81" textpieces="0" top="419" width="359">all algorithms but the L2-R algorithm. The main memory</text>
2 <text font="3" height="13" left="81" textpieces="0" top="435" width="359">optimizations of the L2-R algorithm cause many random ac-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="451" width="359">cesses which hurt performance. We therefore mark the L2-R</text>
2 <text font="3" height="13" left="81" textpieces="0" top="466" width="200">algorithm as not nished (DNF).</text>
2 <text font="3" height="13" left="94" textpieces="0" top="482" width="345">We now examine the impact of the relative size of the rela-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="498" width="359">tions R and S. We xed the cardinality of the relation S to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="513" width="359">be 16M tuples, making |R| = |S|, and we plot the cycles per</text>
2 <text font="3" height="13" left="81" textpieces="0" top="529" width="359">output tuple for the uniform dataset when running on the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="545" width="359">Intel Nehalem in Figure 6. First, the partitioning time in-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="560" width="359">creases proportionally to |R| + |S|. Second, the build phase</text>
2 <text font="3" height="13" left="81" textpieces="0" top="576" width="358">becomes signicant, taking at least 25% of the total join</text>
2 <text font="3" height="13" left="81" textpieces="0" top="592" width="359">completion time. The probe phase, however, is at most 30%</text>
2 <text font="3" height="13" left="81" textpieces="0" top="607" width="359">slower, and less aected by the cardinality of the relation R.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="623" width="359">Overall, all the algorithms are slower when |R| = |S| because</text>
2 <text font="3" height="13" left="81" textpieces="0" top="639" width="358">they have to process more data, but the no partitioning algo-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="654" width="359">rithm is slightly favored because it avoids partitioning both</text>
2 <text font="3" height="13" left="81" textpieces="0" top="670" width="92">input relations.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="686" width="345">The results show that no join algorithm is particularly sen-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="702" width="359">sitive to our selection of input relation cardinalities, there-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="717" width="359">fore our ndings are expected to hold across a broader spec-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="733" width="359">trum of cardinalities. The outcome of the experiments for</text>
2 <text font="3" height="13" left="81" textpieces="0" top="749" width="310">the Sun UltraSPARC T2 is similar, and is omitted.</text>
2 <text font="1" height="16" left="81" textpieces="1" top="777" width="218">4.10  Selectivity experiment</text>
2 <text font="3" height="13" left="94" textpieces="0" top="799" width="345">We now turn our attention to how join selectivity aects</text>
2 <text font="3" height="13" left="81" textpieces="0" top="815" width="359">performance. As all our original datasets are examples of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="831" width="359">joins between primary and foreign keys, all the experiments</text>
2 <text font="3" height="13" left="81" textpieces="0" top="846" width="359">that have been presented so far have a selectivity of 100%.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="862" width="359">For this experiment we created two dierent S relations that</text>
2 <text font="3" height="13" left="81" textpieces="0" top="878" width="359">have the same cardinality but only 50% and 12.5% of the tu-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="893" width="359">ples join with a tuple in the relation R. The key distribution</text>
2 <text font="3" height="13" left="81" textpieces="0" top="909" width="65">is uniform.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="925" width="345">Results for the Intel Nehalem are shown Figure 7(a). De-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="940" width="359">creasing join selectivity has a marginal benet on the probe</text>
2 <text font="3" height="13" left="81" textpieces="0" top="956" width="359">phase, but the other two phases are unaected. The out-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="972" width="359">come of the same experiment on Sun UltraSPARC T2 is</text>
2 <text font="3" height="13" left="81" textpieces="0" top="987" width="359">shown in Figure 7(b). In this architecture, the benet of a</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1003" width="327">small join selectivity on the probe phase is signicant.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="1019" width="345">Inspecting the performance counters in this experiment</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">revealed additional insights. Across all the architectures,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1050" width="359">the code path length (i.e. instructions executed) increases as</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1066" width="358">join selectivity increases. The Intel Nehalem is practically</text>
=============================== COL ===================================
2 <text font="3" height="13" left="475" textpieces="0" top="85" width="359">insensitive to dierent join selectivities, because its out-of-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="101" width="358">order execution manages to overlap the data transfer with</text>
2 <text font="3" height="13" left="475" textpieces="0" top="117" width="359">the byte shuing that is required to assemble the output</text>
2 <text font="3" height="13" left="475" textpieces="0" top="133" width="359">tuple. On the other hand, for the Sun UltraSPARC T2 ma-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="148" width="359">chine, there is a strong linear correlation between the code</text>
2 <text font="3" height="13" left="475" textpieces="0" top="164" width="359">path length and the cycles that are required for the probe</text>
2 <text font="3" height="13" left="475" textpieces="0" top="180" width="359">phase to complete. The in-order Sun UltraSPARC T2 can-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="195" width="359">not automatically extract the instruction-level parallelism of</text>
2 <text font="3" height="13" left="475" textpieces="0" top="211" width="359">the probe phase, unless the programmer explicitly expresses</text>
2 <text font="3" height="13" left="475" textpieces="0" top="227" width="172">it by using multiple threads.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="253" width="146">4.11  Implications</text>
2 <text font="3" height="13" left="489" textpieces="0" top="275" width="345">These results imply that DBMSs must reconsider their</text>
2 <text font="3" height="13" left="475" textpieces="0" top="291" width="358">join algorithms for current and future multi-core processors.</text>
2 <text font="3" height="13" left="475" textpieces="0" top="307" width="359">First, modern processors are very eective in hiding cache</text>
2 <text font="3" height="13" left="475" textpieces="0" top="322" width="359">miss latencies through multi-threading (SMT), as it is shown</text>
2 <text font="3" height="13" left="475" textpieces="0" top="338" width="359">in Tables 5 and 6. Second, optimizing for cache performance</text>
2 <text font="3" height="13" left="475" textpieces="0" top="354" width="359">requires partitioning, and this has additional computation</text>
2 <text font="3" height="13" left="475" textpieces="0" top="369" width="359">and synchronization overheads, and necessitates elaborate</text>
2 <text font="3" height="13" left="475" textpieces="0" top="385" width="359">load balancing techniques to deal with skew. These costs of</text>
2 <text font="3" height="13" left="475" textpieces="0" top="401" width="359">partitioning on a modern multi-core machine can be higher</text>
2 <text font="3" height="13" left="475" textpieces="0" top="416" width="359">than the benet of an increased cache hit rate, especially on</text>
2 <text font="3" height="13" left="475" textpieces="0" top="432" width="358">skewed datasets (as shown in Figures 2 and 3.) To fully</text>
2 <text font="3" height="13" left="475" textpieces="0" top="448" width="359">leverage the current and future CPUs, high performance</text>
2 <text font="3" height="13" left="475" textpieces="0" top="463" width="359">main memory designs have to achieve good cache and TLB</text>
2 <text font="3" height="13" left="475" textpieces="0" top="479" width="359">performance, while fully exploiting SMT, and minimizing</text>
2 <text font="3" height="13" left="475" textpieces="0" top="495" width="132">synchronization costs.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="531" width="180">5.  RELATED WORK</text>
2 <text font="3" height="13" left="489" textpieces="0" top="553" width="345">There is a rich history of studying hash join performance</text>
2 <text font="3" height="13" left="475" textpieces="0" top="569" width="358">for main memory database systems, starting with the early</text>
2 <text font="3" height="13" left="475" textpieces="0" top="584" width="358">work of DeWitt et al. [7]. A decade later Shatdal et al. [16]</text>
2 <text font="3" height="13" left="475" textpieces="0" top="600" width="359">studied cache-conscious algorithms for query execution and</text>
2 <text font="3" height="13" left="475" textpieces="0" top="616" width="359">discovered that the probe phase dominates the overall hash</text>
2 <text font="3" height="13" left="475" textpieces="0" top="631" width="359">join processing time. They also showed that hash join com-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="647" width="359">putation can be sped up if both the build and probe relations</text>
2 <text font="3" height="13" left="475" textpieces="0" top="663" width="239">are partitioned so as to t in the cache.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="678" width="345">Ailamaki et al. [1] studied where DBMSs spend their time</text>
2 <text font="3" height="13" left="475" textpieces="0" top="694" width="360">on modern processors, whereas Manegold et al. [12] inspected</text>
2 <text font="3" height="13" left="475" textpieces="0" top="710" width="359">the time breakdown for a hash join operation. Both papers</text>
2 <text font="3" height="13" left="475" textpieces="0" top="725" width="358">break down the query execution time by examining perfor-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="741" width="359">mance counters, and single out cache and TLB misses as the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="757" width="358">two primary culprits for suboptimal performance in main</text>
2 <text font="3" height="13" left="475" textpieces="0" top="773" width="359">memory processing. A follow-up paper [13] presented a cost</text>
2 <text font="3" height="13" left="475" textpieces="0" top="788" width="358">model on how to optimize the performance of the radix join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="804" width="191">algorithm on a uniprocessor [2].</text>
2 <text font="3" height="13" left="489" textpieces="0" top="820" width="345">Ross [15] presented a more ecient way to improve the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="835" width="359">performance of hash joins by using cuckoo hashing [14] and</text>
2 <text font="3" height="13" left="475" textpieces="0" top="851" width="359">SIMD instructions. Garcia and Korth [9] have studied the</text>
2 <text font="3" height="13" left="475" textpieces="0" top="867" width="358">benets of using simultaneous multi-threading for hash join</text>
2 <text font="3" height="13" left="475" textpieces="0" top="882" width="358">processing. Graefe et al. [10] described how hash-based algo-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="898" width="359">rithms can improve the performance of a commercial DBMS.</text>
2 <text font="3" height="13" left="489" textpieces="0" top="914" width="345">Finally, there has been prior work in handling skew during</text>
2 <text font="3" height="13" left="475" textpieces="0" top="930" width="359">hash join processing. The experiments with a high number</text>
2 <text font="3" height="13" left="475" textpieces="0" top="945" width="359">of partitions that we presented in Section 4.4 are an exten-</text>
2 <text font="3" height="13" left="475" textpieces="0" top="961" width="359">sion of an idea by DeWitt et al. [8] for a main memory,</text>
2 <text font="3" height="13" left="475" textpieces="0" top="976" width="145">multi-core environment.</text>
2 <text font="1" height="16" left="475" textpieces="1" top="1013" width="348">6.  CONCLUSIONS AND FUTURE WORK</text>
2 <text font="3" height="13" left="489" textpieces="0" top="1034" width="345">The rapidly evolving multi-core landscape requires that</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1050" width="359">DBMSs carefully consider the interactions between query</text>
2 <text font="3" height="13" left="475" textpieces="0" top="1066" width="359">processing algorithms and the underlying hardware. In this</text>
=============================== PAGE ===================================
=============================== COL ===================================
2 <text font="10" height="7" left="167" textpieces="0" top="242" width="4">0</text>
2 <text font="10" height="7" left="163" textpieces="0" top="226" width="8">10</text>
2 <text font="10" height="7" left="163" textpieces="0" top="210" width="8">20</text>
2 <text font="10" height="7" left="163" textpieces="0" top="194" width="8">30</text>
2 <text font="10" height="7" left="163" textpieces="0" top="178" width="8">40</text>
2 <text font="10" height="7" left="163" textpieces="0" top="162" width="8">50</text>
2 <text font="10" height="7" left="163" textpieces="0" top="145" width="8">60</text>
2 <text font="10" height="7" left="163" textpieces="0" top="129" width="8">70</text>
2 <text font="10" height="7" left="163" textpieces="0" top="113" width="8">80</text>
2 <text font="10" height="7" left="163" textpieces="0" top="97" width="8">90</text>
2 <text font="10" height="7" left="159" textpieces="0" top="81" width="12">100</text>
2 <text font="10" height="7" left="205" textpieces="1" top="255" width="13">NO     SN</text>
2 <text font="10" height="7" left="232" textpieces="1" top="259" width="14">L2-S     L2-R</text>
2 <text font="10" height="7" left="287" textpieces="1" top="255" width="14">NO     SN</text>
2 <text font="10" height="7" left="315" textpieces="1" top="259" width="14">L2-S     L2-R</text>
2 <text font="10" height="7" left="370" textpieces="1" top="255" width="14">NO     SN</text>
2 <text font="10" height="7" left="398" textpieces="1" top="259" width="13">L2-S     L2-R</text>
2 <text font="10" height="7" left="149" textpieces="0" top="196" width="0">Cycles per output tuple</text>
2 <text font="10" height="7" left="276" textpieces="0" top="297" width="46">Join selectivity</text>
2 <text font="10" height="7" left="373" textpieces="2" top="282" width="-150">100%                                       50%                                      12%</text>
2 <text font="11" height="9" left="226" textpieces="2" top="85" width="163">partition            build            probe</text>
2 <text font="3" height="13" left="230" textpieces="0" top="310" width="107">(a) Intel Nehalem</text>
2 <text font="10" height="7" left="514" textpieces="0" top="242" width="4">0</text>
2 <text font="10" height="7" left="510" textpieces="0" top="226" width="8">10</text>
2 <text font="10" height="7" left="510" textpieces="0" top="210" width="8">20</text>
2 <text font="10" height="7" left="510" textpieces="0" top="194" width="8">30</text>
2 <text font="10" height="7" left="510" textpieces="0" top="178" width="8">40</text>
2 <text font="10" height="7" left="510" textpieces="0" top="162" width="8">50</text>
2 <text font="10" height="7" left="510" textpieces="0" top="145" width="8">60</text>
2 <text font="10" height="7" left="510" textpieces="0" top="129" width="8">70</text>
2 <text font="10" height="7" left="510" textpieces="0" top="113" width="8">80</text>
2 <text font="10" height="7" left="510" textpieces="0" top="97" width="8">90</text>
2 <text font="10" height="7" left="506" textpieces="0" top="81" width="12">100</text>
2 <text font="10" height="7" left="552" textpieces="1" top="255" width="14">NO     SN</text>
2 <text font="10" height="7" left="579" textpieces="1" top="259" width="14">L2-S     L2-R</text>
2 <text font="10" height="7" left="635" textpieces="1" top="255" width="13">NO     SN</text>
2 <text font="10" height="7" left="662" textpieces="1" top="259" width="14">L2-S     L2-R</text>
2 <text font="10" height="7" left="717" textpieces="1" top="255" width="14">NO     SN</text>
2 <text font="10" height="7" left="745" textpieces="1" top="259" width="14">L2-S     L2-R</text>
2 <text font="10" height="7" left="496" textpieces="0" top="196" width="0">Cycles per output tuple</text>
2 <text font="10" height="7" left="623" textpieces="0" top="297" width="46">Join selectivity</text>
2 <text font="10" height="7" left="720" textpieces="2" top="282" width="-150">100%                                       50%                                      12%</text>
2 <text font="11" height="9" left="573" textpieces="2" top="85" width="163">partition            build            probe</text>
2 <text font="3" height="13" left="556" textpieces="0" top="310" width="150">(b) Sun UltraSPARC T2</text>
2 <text font="3" height="13" left="81" textpieces="0" top="333" width="753">Figure 7: Sensitivity to join selectivity. Increasing join selectivity impacts the critical path for the Sun</text>
2 <text font="3" height="13" left="81" textpieces="0" top="348" width="753">UltraSPARC T2, while the out-of-order execution on Intel Nehalem overlaps computation with data transfer.</text>
2 <text font="3" height="13" left="81" textpieces="0" top="386" width="359">paper we examine these interactions when executing a hash</text>
2 <text font="3" height="13" left="81" textpieces="0" top="402" width="359">join operation in a main memory DBMS. We implement</text>
2 <text font="3" height="13" left="81" textpieces="0" top="417" width="359">a family of main memory hash join algorithms that vary in</text>
2 <text font="3" height="13" left="81" textpieces="0" top="433" width="359">the way that they implement the partition, build, and probe</text>
2 <text font="3" height="13" left="81" textpieces="0" top="449" width="253">phases of a canonical hash join algorithm.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="464" width="345">We also evaluate our algorithms on two dierent multi-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="480" width="359">core processor architectures. Our results show that a simple</text>
2 <text font="3" height="13" left="81" textpieces="0" top="496" width="359">hash join technique that does not do any partitioning of the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="512" width="359">input relations often outperforms the other more complex</text>
2 <text font="3" height="13" left="81" textpieces="0" top="527" width="359">partitioning-based join alternatives. In addition, the relative</text>
2 <text font="3" height="13" left="81" textpieces="0" top="543" width="359">performance of this simple hash join technique rapidly im-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="559" width="359">proves with increasing skew, and it outperforms every other</text>
2 <text font="3" height="13" left="81" textpieces="0" top="574" width="345">algorithm in the presence of even small amounts of skew.</text>
2 <text font="3" height="13" left="94" textpieces="0" top="590" width="345">Minimizing cache misses requires additional computation,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="606" width="359">synchronization and load balancing to cope with skew. As</text>
2 <text font="3" height="13" left="81" textpieces="0" top="621" width="359">our experiments show, these costs on a modern multi-core</text>
2 <text font="3" height="13" left="81" textpieces="0" top="637" width="359">machine can be higher than the benet of an increased cache</text>
2 <text font="3" height="13" left="81" textpieces="0" top="653" width="359">hit rate. To fully leverage the current and future CPUs, high</text>
2 <text font="3" height="13" left="81" textpieces="0" top="669" width="359">performance main memory designs have to consider how to</text>
2 <text font="3" height="13" left="81" textpieces="0" top="684" width="359">minimize computation and synchronization costs, and fully</text>
2 <text font="3" height="13" left="81" textpieces="0" top="700" width="359">exploit simultaneous multi-threading, in addition to main-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="715" width="359">taining good cache and TLB behavior. While a large part of</text>
2 <text font="3" height="13" left="81" textpieces="0" top="731" width="359">the previous work in this area has mostly focused on mini-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="747" width="359">mizing cache and TLB misses for database query processing</text>
2 <text font="3" height="13" left="81" textpieces="0" top="763" width="359">tasks, our work here suggests that paying attention to the</text>
2 <text font="3" height="13" left="81" textpieces="0" top="778" width="359">computation and synchronization costs is also very impor-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="794" width="359">tant in modern processors. This work points to a rich direc-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="810" width="359">tion for future work in exploring the design of more complex</text>
2 <text font="3" height="13" left="81" textpieces="0" top="825" width="359">query processing techniques (beyond single joins) that con-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="841" width="359">sider the joint impact of computation, synchronization costs,</text>
2 <text font="3" height="13" left="81" textpieces="0" top="857" width="216">load balancing, and cache behavior.</text>
2 <text font="1" height="16" left="81" textpieces="0" top="900" width="140">Acknowledgments</text>
2 <text font="3" height="13" left="81" textpieces="0" top="924" width="359">We thank David DeWitt for his deeply insightful comments</text>
2 <text font="3" height="13" left="81" textpieces="0" top="940" width="359">on this paper. We also thank the reviewers of this paper</text>
2 <text font="3" height="13" left="81" textpieces="0" top="955" width="359">and Willis Lang for their feedback on an earlier draft of this</text>
2 <text font="3" height="13" left="81" textpieces="0" top="971" width="359">paper. David Wood and the Wisconsin Multifacet project</text>
2 <text font="3" height="13" left="81" textpieces="0" top="987" width="359">were invaluable supporters of this project and gave us ex-</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1002" width="359">clusive access to their hardware, and we thank them. This</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1018" width="358">work was supported in part by a grant from the Microsoft</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1034" width="359">Jim Gray Systems Lab, and in part by the National Science</text>
2 <text font="3" height="13" left="81" textpieces="0" top="1049" width="341">Foundation under grants IIS-0963993 and CNS-0551401.</text>
=============================== COL ===================================
2 <text font="1" height="16" left="475" textpieces="1" top="384" width="152">7.  REFERENCES</text>
2 <text font="4" height="12" left="482" textpieces="0" top="410" width="336">[1] A. Ailamaki, D. J. DeWitt, M. D. Hill, and D. A. Wood.</text>
2 <text font="4" height="12" left="502" textpieces="0" top="423" width="316">DBMSs on a modern processor: Where does time go? In</text>
2 <text font="4" height="11" left="502" textpieces="0" top="437" width="159">VLDB, pages 266277, 1999.</text>
2 <text font="4" height="12" left="481" textpieces="0" top="451" width="333">[2] P. A. Boncz, S. Manegold, and M. L. Kersten. Database</text>
2 <text font="4" height="12" left="502" textpieces="0" top="465" width="309">architecture optimized for the new bottleneck: Memory</text>
2 <text font="4" height="12" left="502" textpieces="0" top="478" width="204">access. In VLDB, pages 5465, 1999.</text>
2 <text font="4" height="12" left="481" textpieces="0" top="493" width="332">[3] J. Cieslewicz, W. Mee, and K. A. Ross. Cache-conscious</text>
2 <text font="4" height="12" left="502" textpieces="0" top="507" width="308">buering for database operators with state. In DaMoN,</text>
2 <text font="4" height="12" left="502" textpieces="0" top="520" width="103">pages 4351, 2009.</text>
2 <text font="4" height="12" left="482" textpieces="0" top="535" width="330">[4] J. Cieslewicz and K. A. Ross. Data partitioning on chip</text>
2 <text font="4" height="12" left="502" textpieces="0" top="548" width="264">multiprocessors. In DaMoN, pages 2534, 2008.</text>
2 <text font="4" height="12" left="481" textpieces="0" top="563" width="322">[5] J. Cieslewicz, K. A. Ross, and I. Giannakakis. Parallel</text>
2 <text font="4" height="12" left="502" textpieces="0" top="577" width="277">buers for chip multiprocessors. In DaMoN, 2007.</text>
2 <text font="4" height="12" left="481" textpieces="0" top="592" width="344">[6] D. J. DeWitt and J. Gray. Parallel database systems: The</text>
2 <text font="4" height="12" left="502" textpieces="0" top="605" width="319">future of database processing or a passing fad? SIGMOD</text>
2 <text font="4" height="11" left="502" textpieces="0" top="619" width="158">Record, 19(4):104112, 1990.</text>
2 <text font="4" height="12" left="481" textpieces="0" top="634" width="306">[7] D. J. DeWitt, R. H. Katz, F. Olken, L. D. Shapiro,</text>
2 <text font="4" height="12" left="502" textpieces="0" top="647" width="280">M. Stonebraker, and D. A. Wood. Implementation</text>
2 <text font="4" height="12" left="502" textpieces="0" top="661" width="278">techniques for main memory database systems. In</text>
2 <text font="4" height="11" left="502" textpieces="0" top="675" width="217">SIGMOD Conference, pages 18, 1984.</text>
2 <text font="4" height="12" left="481" textpieces="0" top="689" width="310">[8] D. J. DeWitt, J. F. Naughton, D. A. Schneider, and</text>
2 <text font="4" height="12" left="502" textpieces="0" top="702" width="311">S. Seshadri. Practical skew handling in parallel joins. In</text>
2 <text font="4" height="11" left="502" textpieces="0" top="716" width="146">VLDB, pages 2740, 1992.</text>
2 <text font="4" height="12" left="481" textpieces="0" top="731" width="344">[9] P. Garcia and H. F. Korth. Database hash-join algorithms</text>
2 <text font="4" height="12" left="502" textpieces="0" top="744" width="282">on multithreaded computer architectures. In Conf.</text>
2 <text font="4" height="11" left="502" textpieces="0" top="758" width="239">Computing Frontiers, pages 241252, 2006.</text>
2 <text font="4" height="12" left="475" textpieces="0" top="773" width="353">[10] G. Graefe, R. Bunker, and S. Cooper. Hash joins and hash</text>
2 <text font="4" height="12" left="502" textpieces="0" top="786" width="309">teams in Microsoft SQL Server. In VLDB, pages 8697,</text>
2 <text font="4" height="12" left="502" textpieces="0" top="800" width="29">1998.</text>
2 <text font="4" height="12" left="475" textpieces="0" top="815" width="317">[11] C. Kim, E. Sedlar, J. Chhugani, T. Kaldewey, A. D.</text>
2 <text font="4" height="12" left="502" textpieces="0" top="828" width="319">Nguyen, A. D. Blas, V. W. Lee, N. Satish, and P. Dubey.</text>
2 <text font="4" height="12" left="502" textpieces="0" top="841" width="290">Sort vs. hash revisited: Fast join implementation on</text>
2 <text font="4" height="12" left="502" textpieces="0" top="855" width="319">modern multi-core CPUs. PVLDB, 2(2):13781389, 2009.</text>
2 <text font="4" height="12" left="475" textpieces="0" top="870" width="319">[12] S. Manegold, P. A. Boncz, and M. L. Kersten. What</text>
2 <text font="4" height="12" left="502" textpieces="0" top="883" width="295">happens during a join? Dissecting CPU and memory</text>
2 <text font="4" height="12" left="502" textpieces="0" top="897" width="292">optimization eects. In VLDB, pages 339350, 2000.</text>
2 <text font="4" height="12" left="475" textpieces="0" top="912" width="350">[13] S. Manegold, P. A. Boncz, and M. L. Kersten. Optimizing</text>
2 <text font="4" height="12" left="502" textpieces="0" top="925" width="300">main-memory join on modern hardware. IEEE Trans.</text>
2 <text font="4" height="11" left="502" textpieces="0" top="939" width="223">Knowl. Data Eng., 14(4):709730, 2002.</text>
2 <text font="4" height="12" left="475" textpieces="0" top="953" width="352">[14] R. Pagh and F. F. Rodler. Cuckoo hashing. J. Algorithms,</text>
2 <text font="4" height="12" left="502" textpieces="0" top="967" width="113">51(2):122144, 2004.</text>
2 <text font="4" height="12" left="475" textpieces="0" top="982" width="354">[15] K. A. Ross. Ecient hash probes on modern processors. In</text>
2 <text font="4" height="11" left="502" textpieces="0" top="996" width="168">ICDE, pages 12971301, 2007.</text>
2 <text font="4" height="12" left="475" textpieces="0" top="1010" width="353">[16] A. Shatdal, C. Kant, and J. F. Naughton. Cache conscious</text>
2 <text font="4" height="12" left="502" textpieces="0" top="1024" width="329">algorithms for relational query processing. In VLDB, pages</text>
2 <text font="4" height="12" left="502" textpieces="0" top="1037" width="81">510521, 1994.</text>
2 <text font="4" height="12" left="475" textpieces="0" top="1052" width="337">[17] M. Stonebraker. The case for shared nothing. In HPTS,</text>
2 <text font="4" height="12" left="502" textpieces="0" top="1066" width="29">1985.</text>
